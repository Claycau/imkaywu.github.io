<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>The Journey Is the Reward</title>
 <link href="http://lhzhang.com/atom.xml" rel="self"/>
 <link href="http://lhzhang.com/"/>
 <updated>2014-01-18T00:19:40+08:00</updated>
 <id>http://lhzhang.com/</id>
 <author>
   <name>Linghua Zhang</name>
   <email>linghua.zhang@me.com</email>
 </author>

 
 <entry>
   <title>Cross Validation (An implementation to find the optimal parameters for LIBSVM)</title>
   <link href="http://lhzhang.com/2014/01/16/cross-validation.html"/>
   <updated>2014-01-16T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/16/cross-validation</id>
   <content type="html">&lt;h2&gt;Brief Introduction&lt;/h2&gt;

&lt;p&gt;Cross-validation, sometimes called rotation estimation, is a model validation technique for assessing how the results of a statistical analysis will generalize to an independent data set. It is mainly used in settings where the goal is prediction, and one wants to estimate how accurately a predictive model will perform in practice. It is worth highlighting that in a prediction problem, a model is usually given a dataset of known data on which training is run (training dataset), and a dataset of unknown data (or first seen data) against which the model is tested (testing dataset). The goal of cross validation is to define a dataset to &quot;test&quot; the model in the training phase (i.e., the validation dataset), in order to limit problems like overfitting, give an insight on how the model will generalize to an independent data set (i.e., an unknown dataset, for instance from a real problem), etc.&lt;/p&gt;

&lt;p&gt;One round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, multiple rounds of cross-validation are performed using different partitions, and the validation results are averaged over the rounds.&lt;/p&gt;

&lt;h2&gt;Common types of cross-validation&lt;/h2&gt;

&lt;h3&gt;K-fold cross-validation&lt;/h3&gt;

&lt;p&gt;In k-fold cross-validation, the original sample is randomly partitioned into k equal size subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining &lt;code&gt;k − 1&lt;/code&gt; subsamples are used as training data. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data. The k results from the folds can then be averaged (or otherwise combined) to produce a single estimation. The advantage of this method over repeated random sub-sampling is that all observations are used for both training and validation, and each observation is used for validation exactly once. 10-fold cross-validation is commonly used, but in general k remains an unfixed parameter.&lt;/p&gt;

&lt;h3&gt;2-fold cross-validation&lt;/h3&gt;

&lt;p&gt;This is the simplest variation of k-fold cross-validation. Also, called holdout method. For each fold, we randomly assign data points to two sets s0 and s1, so that both sets are equal size (this is usually implemented by shuffling the data array and then splitting it in two). We then train on s0 and test on s1, followed by training on s1 and testing on s0.&lt;/p&gt;

&lt;p&gt;This has the advantage that our training and test sets are both large, and each data point is used for both training and validation on each fold.&lt;/p&gt;

&lt;h3&gt;Repeated random sub-sampling validation&lt;/h3&gt;

&lt;p&gt;This method randomly splits the dataset into training and validation data. For each such split, the model is fit to the training data, and predictive accuracy is assessed using the validation data. The results are then averaged over the splits. The advantage of this method (over k-fold cross validation) is that the proportion of the training/validation split is not dependent on the number of iterations (folds). The disadvantage of this method is that some observations may never be selected in the validation subsample, whereas others may be selected more than once. In other words, validation subsets may overlap. This method also exhibits Monte Carlo variation, meaning that the results will vary if the analysis is repeated with different random splits.&lt;/p&gt;

&lt;h3&gt;Leave-one-out cross-validation&lt;/h3&gt;

&lt;p&gt;Leave-one-out cross-validation (LOOCV) involves using a single observation from the original sample as the validation data, and the remaining observations as the training data. This is repeated such that each observation in the sample is used once as the validation data. This is the same as a K-fold cross-validation with K being equal to the number of observations in the original sampling.&lt;/p&gt;

&lt;h2&gt;An example: 10-fold cross-validation&lt;/h2&gt;

&lt;p&gt;将数据集分成十分，轮流将其中9份作为训练数据，1份作为测试数据，进行试验。每次试验都会得出相应的正确率（或差错率）。10次的结果的正确率（或差错率）的平均值作为对算法精度的估计，一般还需要进行多次10-fold cross-validation（例如10次10-fold cross-validation），再求其均值，作为对算法准确性的估计。&lt;/p&gt;

&lt;p&gt;之所以选择将数据集分为10份，是因为通过利用大量数据集、使用不同学习技术进行的大量试验，表明10折是获得最好误差估计的恰当选择，而且也有一些理论根据可以证明这一点。但这并非最终诊断，争议仍然存在。而且似乎5折或者20折与10折所得出的结果也相差无几。&lt;/p&gt;

&lt;h2&gt;An implementation of cross-validation to find the optimal parameters for LIBSVM.&lt;/h2&gt;

&lt;p&gt;The artical and source code are in &lt;a href=&quot;http://imkaywu.com/2014/01/15/find-the-optimal-parameter.html&quot;&gt;another post&lt;/a&gt;, go check it out.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hand Gesture Recognition</title>
   <link href="http://lhzhang.com/2014/01/16/Hand-gesture-recognition.html"/>
   <updated>2014-01-16T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/16/Hand-gesture-recognition</id>
   <content type="html">&lt;p&gt;This is a post that gives a brief description of the algorithm of hand gesture recognition that I developed. It serves as a reminder of what has been done and what remains to be done. You can download the codes in &lt;a href=&quot;https://github.com/imkaywu/Gesture-Recognition-SVM&quot;&gt;Github&lt;/a&gt;, feel free to try out and change the code.Let me introduce our algorithm step by step.&lt;/p&gt;

&lt;blockquote&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/Find-the-contour-of-the-hand-gestures.html&quot;&gt;Find the contour points and connect them in a consecutive manner&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/Find-the-centroid-of-the-hand-gestures.html&quot;&gt;Find the centroid of hand gesture using &lt;strong&gt;distance transform&lt;/strong&gt;.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/Find-the-direction-of-hand-gestures.html&quot;&gt;Find the direction of the hand gesture using the relative positions of contour points (using just Step 1).&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/Transform-to-time-series-curve.html&quot;&gt;Transform the hand contour (points above the centroid, which contribute more to the hand direction) into a &lt;em&gt;time-series curve&lt;/em&gt;.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2014/01/12/Find-the-fingertips-and-fingerroots.html&quot;&gt;Find the initial positions of the fingertips and fingerroots (using just Step 1).&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2014/01/12/Find-the-fingertips-and-fingerroots.html&quot;&gt;Refine the positions of fingertips and fingerroots(using Step 2).&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/Find-the-direction-of-hand-gestures.html&quot;&gt;Find the accurate direction of the hand gesture using the directions of fingers(using Step 2).&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/two-recognition-schemes.html&quot;&gt;Recognition scheme 1: Use the positions of the fingertips and fingerroots for recognition.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/two-recognition-schemes.html&quot;&gt;Recognition scheme 2: Transform the contour points into the time-series curve again and take samples. For each gesture, we can obtain a feature vector. Use Machine Learning algorithm to train the data for recognition.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is pretty much everything about our hand gesture recognition algorithm, the source code is constantly changing because I am still refining the algorithm. If you are interested, please go to my &lt;a href=&quot;https://github.com/imkaywu/&quot;&gt;Github page&lt;/a&gt; to download the &lt;a href=&quot;https://github.com/imkaywu/Gesture-Recognition-SVM&quot;&gt;latest version&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Find the optimal parameters for LIBSVM using cross-validation</title>
   <link href="http://lhzhang.com/2014/01/15/find-the-optimal-parameter.html"/>
   <updated>2014-01-15T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/15/find-the-optimal-parameter</id>
   <content type="html">&lt;h3&gt;目标&lt;/h3&gt;

&lt;p&gt;在SVM算法中，通过交叉验证来确定最佳的参数&lt;code&gt;c&lt;/code&gt;和&lt;code&gt;g&lt;/code&gt;。&lt;/p&gt;

&lt;h3&gt;想法：&lt;/h3&gt;

&lt;p&gt;让c和g在一定的范围里跑(比如 c = 2&lt;sup&gt;(-5),2&lt;sup&gt;(-4),...,2&lt;sup&gt;(5),g&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt; = 2&lt;sup&gt;(-5),2&lt;sup&gt;(-4),...,2&lt;sup&gt;(5)),然后用cross&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt; validation的想法找到准确率最高的c和g,在这里我做了一点修改(纯粹是个人的一点小经验和想法),我改进的是: 因为会有不同的c和g都对应最高的的准确率,我把具有最小c的那组c和g认为是最佳的c和g,因为惩罚参数不能设置太高,很高的惩罚参数能使得validation数据的准确率提高,但过高的惩罚参数c会造成过学习状态,反正从我用SVM到现在,往往都是惩罚参数c过高会导致最终测试集合的准确率并不是很理想。&lt;/p&gt;

&lt;h3&gt;Code:&lt;/h3&gt;

&lt;p&gt;寻找最优化参数的函数(implemented using 10-fold cross-validation)：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function [bestacc,bestc,bestg] = SVMcg(train_label,train,cmin,cmax,gmin,gmax,v,cstep,gstep,accstep)
    % train_label:训练集标签.要求与libsvm工具箱中要求一致.
    % train:训练集.要求与libsvm工具箱中要求一致.
    % cmin:惩罚参数c的变化范围的最小值(取以2为底的对数后),即 c_min = 2^(cmin).默认为 -5
    % cmax:惩罚参数c的变化范围的最大值(取以2为底的对数后),即 c_max = 2^(cmax).默认为 5
    % gmin:参数g的变化范围的最小值(取以2为底的对数后),即 g_min = 2^(gmin).默认为 -5
    % gmax:参数g的变化范围的最小值(取以2为底的对数后),即 g_min = 2^(gmax).默认为 5
    % 
    % v:cross validation的参数,即给测试集分为几部分进行cross validation.默认为 3
    % cstep:参数c步进的大小.默认为 1
    % gstep:参数g步进的大小.默认为 1
    % accstep:最后显示准确率图时的步进大小. 默认为 1.5
    %% about the parameters of SVMcg
    v_def = 10;
    if nargin &amp;lt; 10
        accstep = 1.5;
    end
    if nargin &amp;lt; 8
        accstep = 1.5;
        cstep = 1;
        gstep = 1;
    end
    if nargin &amp;lt; 7
        accstep = 1.5;
        v = v_def;
        cstep = 1;
        gstep = 1;
    end
    if nargin &amp;lt; 6
        accstep = 1.5;
        v = v_def;
        cstep = 1;
        gstep = 1;
        gmax = 5;
    end
    if nargin &amp;lt; 5
        accstep = 1.5;
        v = v_def;
        cstep = 1;
        gstep = 1;
        gmax = 5;
        gmin = -5;
    end
    if nargin &amp;lt; 4
        accstep = 1.5;
        v = v_def;
        cstep = 1;
        gstep = 1;
        gmax = 5;
        gmin = -5;
        cmax = 5;
    end
    if nargin &amp;lt; 3
        accstep = 1.5;
        v = v_def;
        cstep = 1;
        gstep = 1;
        gmax = 5;
        gmin = -5;
        cmax = 5;
        cmin = -5;
    end
    %% X:c Y:g cg:acc
    [X,Y] = meshgrid(cmin:cstep:cmax,gmin:gstep:gmax);
    [m,n] = size(X);
    cg = zeros(m,n);
    %% record acc with different c &amp;amp; g,and find the bestacc with the smallest c
    bestc = 0;
    bestg = 0;
    bestacc = 0;
    basenum = 2;
    for i = 1:m
        for j = 1:n
            cmd = ['-v ',num2str(v),' -c ',num2str( basenum^X(i,j) ),' -g ',num2str( basenum^Y(i,j) )];
            cg(i,j) = svmtrain(train_label, train, cmd);

            if ( cg(i,j) &amp;gt; bestacc || ( cg(i,j) == bestacc &amp;amp;&amp;amp; bestc &amp;gt; basenum^X(i,j) ) )
                bestacc = cg(i,j);
                bestc = basenum^X(i,j);
                bestg = basenum^Y(i,j);
            end
        end
    end
    %% to draw the acc with different c &amp;amp; g
    [C,h] = contour(X,Y,cg,60:accstep:100);
    clabel(C,h,'FontSize',10,'Color','r');
    xlabel('log2c','FontSize',10);
    ylabel('log2g','FontSize',10);
    grid on;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;函数的测试程序：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[ bestacc , bestc , bestg ] = SVMcg( input_feature , train_set );
cmd = [ '-c ' , num2str(bestc) , ' -g ' , num2str(bestg) ];
model = svmtrain( input_feature , train_set , cmd );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;http://www.ilovematlab.cn/thread-47819-1-1.html&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Find the position of fingertips and fingervalleys</title>
   <link href="http://lhzhang.com/2014/01/12/Find-the-fingertips-and-fingerroots.html"/>
   <updated>2014-01-12T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/12/Find-the-fingertips-and-fingerroots</id>
   <content type="html">&lt;h3&gt;Step 1&lt;/h3&gt;

&lt;p&gt;After obtaining the &lt;em&gt;time-series curve&lt;/em&gt;, we can find the positions of the fingertips and fingerroots.&lt;/p&gt;

&lt;p&gt;The fingertips are definded as the locally highest point and the fingervalleys as locally lowest ones. The result of the initial detection of fingertips and fingervalleys is shown below.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The initial detection of fingertips and fingervalleys&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/fingertip&amp;amp;fingervalley.png&quot; alt=&quot;initially detected fingertips and fingervalleys&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then the valid fingertips and their corresponding fingerroots are selected from these candidate points. This is done as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for each fingertip
    find out all the fingervalleys that are on the left and right side of this fingertip (ft), denoted as fv_l and fv_r;
    eliminate invalid fingervalleys using prior knowledge of hand geometry;
    optimal_function(ft,fv_l);
    optimal_function(ft,fv_r);
    find out the fingervalley that maximize the optimal function *optimal_function* and this is regarded as the two fingerroots of this fingertip
endfor
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result of the algorithm is shown as follows. The optimal function I adopt is&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;optimal_function = (distance_ft - distance_fv) ./ distance_fv - 2.5 * (degree_ft - degree_fv) ./ degree_fv;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;The modified detection of fingertips and fingervalleys in both original image and time-series curve&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/fingertip&amp;amp;fingerroot2.png&quot; alt=&quot;detection fingertips and fingerroots&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/fingertip&amp;amp;fingerroot1.png&quot; alt=&quot;detection fingertips and fingerroots&quot; /&gt;
For some images, there are still some refinement needed. For instance, more than 1 detected fingertips may share one or both the fingerroot(s), so there is another optimal function needed to select one fingertip, the optimal function is as follows&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;optimal_function = distance_ft - 0.5 * (distance_fr_l + distance_fr_r);&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Here is the source code of the algorithm written in MATLAB&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function [fingerroot,fingertip]=finger_finder2(degree,norm_distance)
    j=1;
    firstTime=1;
    finger_edge=1;
    length=size(degree,2);
    fingertip=zeros(5,1);
    fingertip_remain=zeros(5,1);
    fingervalley=zeros(1,6);
    fingerroot=zeros(5,2);
    fingerroot_remain=zeros(5,2);
    min_distance=norm_distance(1);
    max_distance=norm_distance(1);
    for i=1:length
        if(norm_distance(i)&amp;lt;min_distance)
            min_distance=norm_distance(i);
            max_distance=norm_distance(i);
            if(min_distance&amp;lt;norm_distance(finger_edge))
                finger_edge=i;
            end
        elseif(norm_distance(i)&amp;lt;max_distance)
            fingertip(j)=i-1;
            fingervalley(j)=finger_edge;
            j=j+1;
            firstTime=~firstTime;
            min_distance=norm_distance(i);
            max_distance=norm_distance(i);
        elseif(norm_distance(i)&amp;gt;max_distance)
            if(firstTime)
                finger_edge=i-1;
                firstTime=~firstTime;
            end
            max_distance=norm_distance(i);
        end
    end

    j=1;
    fingertip_length=find(fingertip,1,'last');
    fingervalley(fingertip_length+1)=size(degree,2);
    for i=1:fingertip_length
        index_left=i;
        index_right=i+1;
        if(i==7)
        end
        if(sum(fingertip_remain)==0||max(norm_distance(fingertip(fingertip_remain(1:find(fingertip_remain,1,'last')))))&amp;lt;norm_distance(fingertip(i)))
            fv_left_all=fingervalley(1:index_left);
        else
            [ft_highest,ft_highest_index]=max(norm_distance(fingertip(fingertip_remain(1:find(fingertip_remain,1,'last')))));
            ft_highest_index=fingertip_remain(ft_highest_index);
            fv_left_all=fingervalley(ft_highest_index+1:index_left);
        end
        fv_right_all=fingervalley(index_right:fingertip_length+1);
%         fv_left_all(norm_distance(fv_left_all)&amp;gt;1.85)=[];
%         fv_right_all(norm_distance(fv_right_all)&amp;gt;1.85)=[];
        fv_left_index=(norm_distance(fingertip(i))-norm_distance(fv_left_all))./norm_distance(fv_left_all)&amp;gt;0.49;
        fv_right_index=(norm_distance(fingertip(i))-norm_distance(fv_right_all))./norm_distance(fv_right_all)&amp;gt;0.49;
        fv_left_all=fv_left_all(fv_left_index);
        fv_right_all=fv_right_all(fv_right_index);

        if(sum(fv_left_index)~=0&amp;amp;&amp;amp;size(fv_left_all,2)&amp;gt;1)
            optim_func_left=(norm_distance(fingertip(i))-norm_distance(fv_left_all))./norm_distance(fv_left_all)-2.5*(degree(fingertip(i))-degree(fv_left_all))./degree(fv_left_all);
            [maxVal,maxInd]=max(optim_func_left);
            fv_left_all=fv_left_all(maxInd);
        end

        if(sum(fv_right_index)~=0&amp;amp;&amp;amp;size(fv_right_index,2)&amp;gt;1)
            optim_func_right=(norm_distance(fingertip(i))-norm_distance(fv_right_index))./norm_distance(fv_right_index)-2.5*(degree(fv_right_index)-degree(fingertip(i)))./degree(fv_right_index);
            [maxVal,maxInd]=max(optim_func_right);
            fv_right_all=fv_right_all(maxInd);
        end

        if(sum(fv_left_index)==0||sum(fv_right_index)==0)
            continue;
        else
            fingertip_remain(j)=i;
            fingerroot_remain(j,:)=[fv_left_all,fv_right_all];
            j=j+1;
        end
    end
    index=find(fingertip_remain==0);
    fingertip_remain(index)=[];
    fingertip_remain=fingertip(fingertip_remain);
    fingerroot_remain(index,:)=[];

    %Eliminate the combinations of fingertip and fingerroots of which the
    %fingerroots are out of bounds
    n=1;
    fingertip_remove=zeros(1,size(fingertip_remain,1));
    for i=1:size(fingertip_remain,1)-1
        for j=i+1:size(fingertip_remain,1)
            if(fingerroot_remain(i,1)&amp;gt;=fingerroot_remain(j,1)||fingerroot_remain(i,2)&amp;gt;fingerroot_remain(j,1))%between the two numbers
                if(sum((norm_distance(fingertip_remain(i))-norm_distance(fingerroot_remain(i,:)))./norm_distance(fingerroot_remain(i,:)))&amp;gt;sum((norm_distance(fingertip_remain(j))-norm_distance(fingerroot_remain(j,:)))./norm_distance(fingerroot_remain(j,:))))
                    fingertip_remove(n)=j;
                else
                    fingertip_remove(n)=i;
                end
                n=n+1;
            end
        end
    end
    fingertip_remove(fingertip_remove==0)=[];
    fingertip_remove=unique(fingertip_remove);
    fingertip_remain(fingertip_remove)=[];
%     fingertip_remain=unique(fingertip_remain);
    fingerroot_remain(fingertip_remove,:)=[];

    %Find out the fingertips that have one more two same fingerroot(s) 
    fingervalley_cato=zeros(size(fingertip_remain,1));
    flag=zeros(1,size(fingertip_remain,1));
    for i=1:size(fingertip_remain,1)-1
        for j=i+1:size(fingertip_remain,1)
            if(sum(fingerroot_remain(i,:)==fingerroot_remain(j,:))&amp;amp;&amp;amp;flag(j)==0)
                fingervalley_cato(i,[2*(j-i)-1,2*(j-i)])=[i,j];
                flag([i,j])=1;
            end
        end
    end

    n=1;
    fingertip=zeros(5,1);
    if(size(fingertip_remain,1)~=1&amp;amp;&amp;amp;sum(sum(fingervalley_cato))~=0)
        for i=1:size(fingervalley_cato,1)
            fingervalley_cato_temp=fingervalley_cato(i,:);
            if(sum(fingervalley_cato_temp)~=0)
                fingertip_index=unique(fingervalley_cato_temp(fingervalley_cato_temp~=0));
                optim_func=zeros(size(fingertip_index,2),1);
                for j=1:size(fingertip_index,2)
                    optim_func(j)=norm_distance(fingertip_remain(fingertip_index(j)))-mean(norm_distance(fingerroot_remain(fingertip_index(j),:)));
                end
                [a,fingertip_pos]=max(optim_func);
                fingertip_pos=fingertip_index(fingertip_pos);
                fingertip(n)=fingertip_remain(fingertip_pos);
                fingerroot(n,:)=fingerroot_remain(fingertip_pos,:);
                n=n+1;
            elseif(flag(i)==0)
                fingertip(n)=fingertip_remain(i);
                fingerroot(n,:)=fingerroot_remain(i,:);
                n=n+1;
            end
        end
    else
        fingertip=fingertip_remain;
        fingerroot=fingerroot_remain;
    end

    finger_remove=fingertip==0;
    fingertip(finger_remove)=[];
    fingerroot(finger_remove,:)=[];
    [fingertip,ft_index]=sort(fingertip);
    fingerroot=fingerroot(ft_index,:);

    if(find(fingertip,1,'last')&amp;gt;1&amp;amp;&amp;amp;(degree(fingerroot(1,2))-degree(fingerroot(1,1)))/(norm_distance(fingertip(1))-mean(norm_distance(fingerroot(1,:))))&amp;gt;0.3)%used to solve noise peak in gesture4 image7
        fingertip(1)=[];
        fingerroot(1,:)=[];
    end

%     figure;
%     plot(degree,norm_distance);
%     hold on;
%     plot(degree(fingertip),norm_distance(fingertip),'r^');
%     plot(degree(fingerroot),norm_distance(fingerroot),'ro');
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After the fingertips and fingerroots are found, they are still in need of some adjustment in order to achievement the best performance. Therefore Step 2 is employed to further refine the positions of fingertips and fingerroots.&lt;/p&gt;

&lt;h3&gt;Step 2&lt;/h3&gt;

&lt;p&gt;It's intuitive to us that if we draw a external rectangle to each finger, the ratio of the area of the finger and the rectangular area should surpass a certain threshold. So this is the main idea of the algorithm to precisely locate the positions of the fingerroots.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;area_ratio = area_finger / area_external_rec;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;First, with the positions of the fingertip and fingerroots, we can know the direction of the finger, which is obtained as follows&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;finger_direction = 0.5 * (direction_ft_fr_l + direction_ft_fr_r);&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then we find the mirror point for each of the fingerroot(the line crosses one fingerroot and its mirror point is perpendicular to finger direction). And whichever combination(fingerroot and its mirror point) is closer to the fingertip, we treat them as the updated fingerroots. Then we calculate the &lt;em&gt;area_ratio&lt;/em&gt;. This process repeats until the &lt;em&gt;area_ratio&lt;/em&gt; surpass a certain threshold. In our code, I use 0.65 as the threshold.&lt;/p&gt;

&lt;p&gt;Here is the refined positions of fingertips and fingerroot, as you can see the differences when compared to the initial ones above. Source code is as follows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The refined detection of fingertips and fingervalleys&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/fingertip&amp;amp;fingerroot_refined.png&quot; alt=&quot;refined detection fingertips and fingervalleys&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%% ----detect the more accurate positions of the fingerroots---- %%
fingertip_length=size(fingertip,1);
fingerroot=zeros(1,2*fingertip_length);
finger_direction=zeros(1,fingertip_length);
for i=1:fingertip_length
    P=[y_array(fingertip(i)),x_array(fingertip(i))];
    fingeredge_start=fingervalley(i,1);
    fingeredge_end=fingervalley(i,2);
    while(true)
        direction_angle=direction_detector3(x_array,y_array,fingertip(i),[fingeredge_start,fingeredge_end]);
        [fingeredge_start,fingeredge_end]=finger_finder3(x_array,y_array,fingertip(i),[fingeredge_start,fingeredge_end],direction_angle);
        %calculate the area of the external rectangle
        Q=[P(1)+10,P(2)-10/tand(direction_angle)];
        n=1;
        dist=zeros(1,fingeredge_end-fingeredge_start+1);
        for j=fingeredge_start:fingeredge_end
            dist(n)=abs(det([P-Q;[y_array(j),x_array(j)]-Q]))/norm(P-Q);
            n=n+1;
        end
        fingerroot1=[y_array(fingeredge_start),x_array(fingeredge_start)];
        fingerroot2=[y_array(fingeredge_end),x_array(fingeredge_end)];
        length=max(dist(1:fingertip(i)-fingeredge_start+1))+max(dist(fingertip(i)-fingeredge_start+1:fingeredge_end-fingeredge_start+1));
        height=abs(det([fingerroot2-fingerroot1;P-fingerroot1]))/norm(fingerroot2-fingerroot1);
        area=length*height;
        %calculate the area of the finger
        finger_area=0;
        finger_top=min(y_array(fingeredge_start:fingeredge_end));
        up=min(y_array([fingeredge_start,fingeredge_end]));
        low=max(y_array([fingeredge_start,fingeredge_end]));
        for j=finger_top:1:low
            if(j&amp;lt;=up)
                x=x_array(fingeredge_start+find(j==y_array(fingeredge_start:fingeredge_end))-1);
                finger_area=finger_area+max(x)-min(x)+1;
            else
                if(up==y_array(fingeredge_end))
                    x=x_array(fingeredge_end)+(x_array(fingeredge_end)-x_array(fingeredge_start))/(up-low)*(j-up);
                    finger_area=finger_area+x-min(x_array(fingeredge_start+find(j==y_array(fingeredge_start:fingeredge_end))-1))+1;
                else
                    x=x_array(fingeredge_start)+(x_array(fingeredge_start)-x_array(fingeredge_end))/(up-low)*(j-up);
                    finger_area=finger_area+max(x_array(fingeredge_start+find(j==y_array(fingeredge_start:fingeredge_end))-1))-x+1;
                end
            end
        end
%             imshow(edge_map);
%             hold on;
%             x_line1=zeros(1,row);
%             y_line=1:row;
%             x_line1(1:y_array(fingertip(i)))=x_array(fingertip(i))+round((y_array(fingertip(i))-(1:y_array(fingertip(i))))./tand(direction_angle));
%             x_line1(y_array(fingertip(i))+1:row)=x_array(fingertip(i))-round(((y_array(fingertip(i))+1:row)-y_array(fingertip(i)))./tand(direction_angle));
%             plot(x_line1,y_line);
%             plot([x_array(fingeredge_start),x_array(fingeredge_end)],[y_array(fingeredge_start),y_array(fingeredge_end)],'r*');

        area_percent=finger_area/area;
        if(area_percent&amp;gt;0.65||(fingeredge_start&amp;gt;fingertip(i)||fingeredge_end&amp;lt;fingertip(i)))
            fingerroot([2*i-1,2*i])=[fingeredge_start,fingeredge_end];
            finger_direction(i)=direction_angle;
            break;
        end
    end
end
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>SVM多分类的方法 (转载)</title>
   <link href="http://lhzhang.com/2014/01/10/SVM%E5%A4%9A%E5%88%86%E7%B1%BB%E7%9A%84%E6%96%B9%E6%B3%95.html"/>
   <updated>2014-01-10T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/10/SVM多分类的方法</id>
   <content type="html">&lt;p&gt;SVM算法最初是为二值分类问题设计的，当处理多类问题时，就需要构造合适的多类分类器。目前，构造SVM多类分类器的方法主要有两类：一类是直接法，直接在目标函数上进行修改，将多个分类面的参数求解合并到一个最优化问题中，通过求解该最优化问题“一次性”实现多类分类。这种方法看似简单，但其计算复杂度比较高，实现起来比较困难，只适合用于小型问题中；另一类是间接法，主要是通过组合多个二分类器来实现多分类器的构造，常见的方法有one-against-one和one-against-all两种。&lt;/p&gt;

&lt;p&gt;a.一对多法（one-versus-rest,简称1-v-r SVMs）。训练时依次把某个类别的样本归为一类,其他剩余的样本归为另一类，这样k个类别的样本就构造出了k个SVM。分类时将未知样本分类为具有最大分类函数值的那类。&lt;/p&gt;

&lt;p&gt;b.一对一法（one-versus-one,简称1-v-1 SVMs）。其做法是在任意两类样本之间设计一个SVM，因此k个类别的样本就需要设计k(k-1)/2个SVM。当对一个未知样本进行分类时，最后得票最多的类别即为该未知样本的类别。Libsvm中的多类分类就是根据这个方法实现的。&lt;/p&gt;

&lt;p&gt;c.层次支持向量机（H-SVMs）。层次分类法首先将所有类别分成两个子类，再将子类进一步划分成两个次级子类，如此循环，直到得到一个单独的类别为止。&lt;/p&gt;

&lt;p&gt;对c和d两种方法的详细说明可以参考论文《支持向量机在多类分类问题中的推广》（计算机工程与应用。2004）&lt;/p&gt;

&lt;p&gt;d.其他多类分类方法。除了以上几种方法外，还有有向无环图SVM（Directed Acyclic Graph SVMs，简称DAG-SVMs）和对类别进行二进制编码的纠错编码SVMs。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/lanseliuying/article/details/1768995&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>LIBSVP简介和安装使用</title>
   <link href="http://lhzhang.com/2014/01/10/LIBSVM.html"/>
   <updated>2014-01-10T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/10/LIBSVM</id>
   <content type="html">&lt;h2&gt;简介&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;LIBSVM&lt;/a&gt;是台湾大学林智仁教授等研究人员开发的一个用于支持向量机分类，回归分析及分布估计的c/c++开源库。另外，它也可以用于解决多类分类问题。LIBSVM的主要特点有：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;各种SVM的表达公式；&lt;/p&gt;

&lt;p&gt;有效的多类分类能力；&lt;/p&gt;

&lt;p&gt;交叉验证功能；&lt;/p&gt;

&lt;p&gt;各种核函数，包括预先计算得到的核矩阵；&lt;/p&gt;

&lt;p&gt;用于非平衡数据的加权svm；&lt;/p&gt;

&lt;p&gt;提供c++和java源代码；&lt;/p&gt;

&lt;p&gt;用于演示SVM分类与回归能力的GUI界面；&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;林智仁教授推荐按照以下的步骤来使用LIBSVM：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;将数据转换到LIBSVM指定的格式；&lt;/p&gt;

&lt;p&gt;对数据进行尺度操作（一般指数据的归一化）；&lt;/p&gt;

&lt;p&gt;考虑RBF（径向基）核函数；&lt;/p&gt;

&lt;p&gt;利用交叉验证来得到最好的参数C和r；&lt;/p&gt;

&lt;p&gt;用最好的C和r来训练所有训练集合；&lt;/p&gt;

&lt;p&gt;测试；&lt;/p&gt;&lt;/blockquote&gt;

&lt;h2&gt;安装&lt;/h2&gt;

&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/cjlin1/libsvm&quot;&gt;下载LIBSVM软件包&lt;/a&gt;,将该软件包解压缩到MATLAB所在目录下的toolbox文件夹下。&lt;/p&gt;

&lt;p&gt;选择编译器： 因为LIBSVM是用C++写的， 为了能在MATLAB中使用，必须通过编译器将C++代码编译成MATLAB可执行的代码（.mexw32）。在MATLAB命令窗口中输入&lt;code&gt;mex -setup&lt;/code&gt;，然后按照提示选择编译器即可。&lt;/p&gt;

&lt;p&gt;编译：编译时必须在LIBSVM/matlab的目录下，执行&lt;code&gt;make&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;测试：下载测试使用的数据heart_scale.mat(注：有C++版本和MATLAB版，要下载MATLAB版本)。然后执行以下命令：&lt;/p&gt;&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;load heart_scale;
model=svmtrain(heart_scale_label,heart_scale_inst);
[predict_label,accuracy,prob_estimates] = svmpredict(heart_scale_label,heart_scale_inst,model,'b');
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果成功的话就可以看到Accuracy。其中heart_scale_label是train的标签，heart_scale_inst是train的feature vector，model是SVM训练出来的模型。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>A Low Complex hand segment and recognition method for human-wearable device-interaction using priority-based scan-line stereo matching</title>
   <link href="http://lhzhang.com/2013/12/05/Paper.html"/>
   <updated>2013-12-05T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2013/12/05/Paper</id>
   <content type="html">&lt;p&gt;Publication List
This is an excerpt of the paper of A Low Complex hand segment and recognition method for human-wearable device-interaction using priority-based scan-line stereo matching. It's about the algorithm of hand gesture recognition, You can refer to another post for a brief description of the algorithm. A PDF version is available below.
&lt;a href=&quot;http://imkaywu.com/paper.pdf&quot;&gt;Ren Y., Wu K., A Low Complex hand segment and recognition method for human-wearable device-interaction using priority-based scan-line stereo matching&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Two Recognition Schemes</title>
   <link href="http://lhzhang.com/2013/11/23/two-recognition-schemes.html"/>
   <updated>2013-11-23T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2013/11/23/two-recognition-schemes</id>
   <content type="html">&lt;h3&gt;Scheme 1&lt;/h3&gt;

&lt;p&gt;After we obtain the accurate hand direction, we can find a relatively fixed reference point in the hand gesture. The reference point is chosen using the following rule. As is shown in the following image.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The line crosses the reference point and the centroid is perpendicular to the hand direction.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/reference_point.png&quot; alt=&quot;reference point&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then we can calculate the degree between the fingertips (or fingerroots) and the reference point. Because the hand direction is rotation invariant and the reference point is relatively fixed, this should suffice to recognition the gestures.&lt;/p&gt;

&lt;h3&gt;Scheme 2&lt;/h3&gt;

&lt;p&gt;We transform the contour points above the centroid into a time-series curve again. Now this time, we don't need to find the fingertips and fingerroots, we take samples in this curve. Because the time-series is the description of the hand profile, this extracted samples also serve as a coarse description of the hand profile. See the following two images.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Samples in the original image&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/sample_original.png&quot; alt=&quot;Samples in the original image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Samples in the time-series curve&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/sample_time_series.png&quot; alt=&quot;edge_finder_unmodified&quot; /&gt;&lt;/p&gt;

&lt;h4&gt;Logistic Regression&lt;/h4&gt;

&lt;p&gt;We then use machine learning algorithm(Logistic Regression) to train the data for recognition. The source code is as follows&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function  result_table = main_logistic_regression_hand
    times = 1;
    result_table = 0;
    for ii = 1 : times
        [ result_table_temp , theta ]= logistic_regression_hand;
        result_table = result_table + result_table_temp;
        save( strcat('theta',num2str(ii),'.mat'),'theta');
    end
    result_table = result_table / times;
end

function [ result_table , theta ] = logistic_regression_hand
    %% Read in data &amp;amp; select data
    str = 'data\Test data\gesture';
    file_index = 2 : 14;
    [ x_all , groung_truth_gesture_index_all , same_gesture_number_all ] = read_in_distance_sample_map_data( str , file_index );
    [ y , train_set , test_set , test_index ] = data_select( x_all , same_gesture_number_all , 0.8 , 'random_on'  );
    %% Traing
    theta = zeros( size( y , 2 ) , size( train_set , 2 ) );%theta(number of gestures, number of features)
    for kk = 1 : size( y , 2 )
        theta(kk,:) = Logistic_Regression_Gradient_Descent_Hand( y( : , kk ) , train_set);
    end
    %% Result
    test_gesture_index = groung_truth_gesture_index_all( test_index );
    test_gesture_number = zeros( length( same_gesture_number_all ) , 1 );
    init_gesture = [ 1 , 1 , 1 , 4 , 4 , 4 , 4 , 8 , 8 , 8 , 8 , 12 , 13 ];
    recognized_gesture_index = zeros( length( test_gesture_index ) ,1 );
    result_table = zeros( length( same_gesture_number_all ) , length( same_gesture_number_all ) );
    result = test_set * ( theta' );
    for ii = 1 : length( same_gesture_number_all )
        test_gesture_number( ii ) = sum( test_gesture_index == ii );
    end
    for ii = 1 : length( same_gesture_number_all )
        [ maxVal , maxInd ] = max( result( sum( test_gesture_number( 1 : ii-1 ) ) + 1 : sum( test_gesture_number( 1 : ii ) ) , init_gesture == init_gesture( ii ) ) , [] , 2 );
        recognized_gesture_index( sum( test_gesture_number( 1 : ii-1 ) ) + 1 : sum( test_gesture_number( 1 : ii ) ) ) = maxInd + init_gesture( ii ) - 1;
    end

    for ii = 1 : length( recognized_gesture_index )
        result_table( recognized_gesture_index(ii) , test_gesture_index( ii ) ) = result_table( recognized_gesture_index(ii) , test_gesture_index( ii ) ) + 1;
    end
    for ii = 1 : length( same_gesture_number_all )
        result_table( : , ii ) = result_table( : , ii ) ./ sum( test_gesture_number( ii ) );
    end
end
%% Logistic Regression and Gradient Descent
function theta = Logistic_Regression_Gradient_Descent_Hand( y , x )
    epsilon = 1e-5;
    num_feature = size( x , 2 );
    theta = zeros( 1 , num_feature );
    jVal = 0;
    jVal_old = 100 * epsilon;
    while( abs( jVal_old - jVal ) &amp;gt;= epsilon )
        jVal_old = jVal;
        theta = Gradient_Descent_hand( y , x , theta );
        jVal = y .* log( h_theta( x , theta) )+ ( 1 - y ) .* log( 1 - h_theta( x , theta) );
        jVal = sum( jVal );
    end
end

function theta = Gradient_Descent_hand( y , x , theta )
    num_feature = size( x , 2 );
    alpha = 0.001;
    tempVal1 = y - h_theta( x , theta );
    tempVal2 = repmat( tempVal1 ,1 , num_feature );
    tempVal3 = tempVal2 .* x;
    tempVal4 = sum( tempVal3 );
    theta = theta + alpha * tempVal4;
end

function hVal = h_theta( x , theta)
    hVal = 1 ./ ( 1 + exp( - x * theta' ) );
end
%% Read in the data of each type of gesture
function [ x , gesture_index , same_gesture_number ] = read_in_distance_sample_map_data( str , file_index )
    x = []; gesture_index = []; same_gesture_number = [];
    new_gesture_index_num = 1;
    for ii = file_index
        load( strcat( str , num2str(ii) , '_test_data') );
        m = size(distance_sample_map,1);
        same_gesture_number = [ same_gesture_number ; m ];
        gesture_index = [ gesture_index ; new_gesture_index_num*ones(m,1)];
        new_gesture_index_num = new_gesture_index_num + 1;
        x = [ x ; distance_sample_map ]; 
    end
    clear ii jj m;
end
%% Select the training set and test set, store separately in x and z; x_all is the gesture set, gesture_number_all is the number of each gesture type, percent is the percentage of training set, CW_random=='random_on' means select the training set randomly.
function [ y , x , z ,index ] = data_select( x_all , gesture_number_all , percent , CW_random )
    dif_gesture_num = size( gesture_number_all , 1 );%Size of each gesture
    feature_num = size( x_all , 2 );
    selected_same_gesture_num = floor( percent * gesture_number_all );%Size of each gesture in the training set
    unselected_same_gesture_num = gesture_number_all - selected_same_gesture_num;%Size of each gesture in the test set

    y = zeros( sum( selected_same_gesture_num ) , dif_gesture_num );
    x = zeros( sum( selected_same_gesture_num ) , feature_num );
    index = zeros( sum( unselected_same_gesture_num ) , 1 );

    for ii = 1 : dif_gesture_num
        if strcmp( CW_random , 'random_on' )
            index_all_random = randperm( gesture_number_all(ii) );
            index_select = index_all_random( 1 : selected_same_gesture_num(ii) );
            index_unselect = index_all_random( selected_same_gesture_num(ii)+1 : end );
        else
            index_select = 1 : selected_same_gesture_num(ii);
            index_unselect = selected_same_gesture_num(ii)+1 : gesture_number_all(ii);
        end

        x( sum( selected_same_gesture_num( 1 : ii -1 ) ) + 1 : sum( selected_same_gesture_num( 1 : ii  ) ) , : ) = x_all( sum( gesture_number_all( 1 : ii -1 ) ) +  index_select , : );
        y( sum( selected_same_gesture_num( 1 : ii -1 ) ) + 1 : sum( selected_same_gesture_num( 1 : ii  ) ) , ii ) = 1;
        index( sum( unselected_same_gesture_num( 1 : ii -1 ) ) + 1 : sum( unselected_same_gesture_num( 1 : ii ) ) ) = sum( gesture_number_all( 1 : ii -1 ) ) + index_unselect;
    end
    z = x_all( index , : );
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Support Vector Machine&lt;/h4&gt;

&lt;p&gt;I recently turned to SVM and thanks to the open code provided by LIBSVM, I implemented the recognition algorithm with quite convience and it achieves much better recognition  results. I used one-versus-one multi-class SVM.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;% one-versus-one
function [ accuracy_train , accuracy_test ] = main_svm_classifier_v3
    tic;
    train_prct = 0.9;
    count = 20;
    accuracy_train = zeros( 13 );
    accuracy_test = zeros( 13 );
    for i = 1 : count
        [ accuracy_train_temp , accuracy_test_temp ] = svm_classifier;
        accuracy_train = accuracy_train + accuracy_train_temp;
        accuracy_test = accuracy_test + accuracy_test_temp;
    end
    accuracy_train = accuracy_train / count;
    accuracy_test = accuracy_test / count;
    cd data\Train' data'\accuracy;
    save( strcat('accuracy_train',num2str(train_prct),'.mat'),'accuracy_train');
    save( strcat('accuracy_test',num2str(train_prct),'.mat'),'accuracy_test');
    toc;
end
function [ accuracy_train , accuracy_test ] = svm_classifier
    %% Read in data and choose the training set
    str = 'data\Test data\gesture';
    train_prct = 0.8;
    file_index = 2 : 14;
    [ x_all , ground_truth_gesture_index_all , same_gesture_number_all ] = read_in_distance_sample_map_data( str , file_index );
    [ y , train_set , test_set , test_index ] = data_select( x_all , same_gesture_number_all , train_prct , 'random_on' );
    %% Training
    num_gesture_type = size( same_gesture_number_all , 1 );
    input_feature=zeros( size( y , 1 ) , 1 );
    for i = 1 : num_gesture_type
        input_feature( y( : , i ) == 1 ) = i;
    end
    cd 'E:\Program Files\MATLAB\R2010b\toolbox\libsvm-3.17\matlab';
    [ bestacc , bestc , bestg ] = SVMcg( input_feature , train_set );
    cmd = [ '-c ' , num2str(bestc) , ' -g ' , num2str(bestg) ];
    model = svmtrain( input_feature , train_set , cmd );
    %% Test
    accuracy_train = zeros( num_gesture_type );
    accuracy_test = zeros( num_gesture_type );
    test_set_index = ground_truth_gesture_index_all( test_index );
    % Predict the training set
    cd 'E:\Program Files\MATLAB\R2010b\toolbox\libsvm-3.17\matlab';
    [ predict_label , accuracy_rate , prob_estimates ] = svmpredict( input_feature , train_set , model , '-q' );
    cd 'E:\Document\Goer\Essay\清华\Kay''s code';
    for i = 1 : size( input_feature , 1 )
        accuracy_train( predict_label( i ) , input_feature( i ) ) = accuracy_train( predict_label( i ) , input_feature( i ) ) + 1;
    end
    for i = 1 : num_gesture_type
        accuracy_train( : , i ) = accuracy_train( : , i ) / sum( accuracy_train( : , i ) );
    end

    % Predict the test set
    cd 'E:\Program Files\MATLAB\R2010b\toolbox\libsvm-3.17\matlab';
    [ predict_label , accuracy_rate , prob_estimates ] = svmpredict( test_set_index , test_set , model , '-q' );
    cd 'E:\Document\Goer\Essay\清华\Kay''s code';
    for i = 1 : size( test_set_index , 1 )
        accuracy_test( predict_label( i ) , test_set_index( i ) ) = accuracy_test( predict_label( i ) , test_set_index( i ) ) + 1;
    end
    for i = 1 : num_gesture_type
        accuracy_test( : , i ) = accuracy_test( : , i ) / sum( accuracy_test( : , i ) );
    end
end

%% Read in the data of each type of gesture
function [ x , gesture_index , same_gesture_number ] = read_in_distance_sample_map_data( str , file_index )
    x = []; gesture_index = []; same_gesture_number = [];
    new_gesture_index_num = 1;
    for ii = file_index
        load( strcat( str , num2str(ii) , '_test_data') );
        m = size(distance_sample_map,1);
        same_gesture_number = [ same_gesture_number ; m ];
        gesture_index = [ gesture_index ; new_gesture_index_num*ones(m,1)];
        new_gesture_index_num = new_gesture_index_num + 1;
        x = [ x ; distance_sample_map ];
    end
    clear ii jj m;
end
%% Select the training set and test set, store separately in x and z; x_all is the gesture set, gesture_number_all is the number of each gesture type, percent is the percentage of training set, CW_random=='random_on' means select the training set randomly.
function [ y , x , z ,index ] = data_select( x_all , gesture_number_all , percent , CW_random )
    dif_gesture_num = size( gesture_number_all , 1 );%Size of each gesture
    feature_num = size( x_all , 2 );
    selected_same_gesture_num = floor( percent * gesture_number_all );%Size of each gesture in the training set
    unselected_same_gesture_num = gesture_number_all - selected_same_gesture_num;%Size of each gesture in the test set

    y = zeros( sum( selected_same_gesture_num ) , dif_gesture_num );
    x = zeros( sum( selected_same_gesture_num ) , feature_num );
    index = zeros( sum( unselected_same_gesture_num ) , 1 );

    for ii = 1 : dif_gesture_num
        if strcmp( CW_random , 'random_on' )
            index_all_random = randperm( gesture_number_all(ii) );
            index_select = index_all_random( 1 : selected_same_gesture_num(ii) );
            index_unselect = index_all_random( selected_same_gesture_num(ii)+1 : end );
        else
            index_select = 1 : selected_same_gesture_num(ii);
            index_unselect = selected_same_gesture_num(ii)+1 : gesture_number_all(ii);
        end

        x( sum( selected_same_gesture_num( 1 : ii -1 ) ) + 1 : sum( selected_same_gesture_num( 1 : ii  ) ) , : ) = x_all( sum( gesture_number_all( 1 : ii -1 ) ) +  index_select , : );
        y( sum( selected_same_gesture_num( 1 : ii -1 ) ) + 1 : sum( selected_same_gesture_num( 1 : ii  ) ) , ii ) = 1;
        index( sum( unselected_same_gesture_num( 1 : ii -1 ) ) + 1 : sum( unselected_same_gesture_num( 1 : ii ) ) ) = sum( gesture_number_all( 1 : ii -1 ) ) + index_unselect;
    end
    z = x_all( index , : );
end
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Transform to Time-series curve</title>
   <link href="http://lhzhang.com/2013/11/23/Transform-to-time-series-curve.html"/>
   <updated>2013-11-23T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2013/11/23/Transform-to-time-series-curve</id>
   <content type="html">&lt;p&gt;After obtaining the contour vertex and the direction of hand, we can transform the contour vertex into a &lt;em&gt;time-series curve&lt;/em&gt;. The &lt;em&gt;time-series curve&lt;/em&gt; records the relative distance between each contour vertex to the centroid starting from the reference point(a relatively fixed point in hand gestures). The horizontal axis denotes the angle between each contour vertex and the reference point relative to the centroid, normalized by 360. The vertical axis denotes the Euclidean distance between the contour vertices and the centroid, normalized by the radius of the inscribed circle. Here is how it's done.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function [degree,norm_distance]=trans_graph1(x_array,y_array,x_center,y_center)
    length=find(x_array, 1, 'last');
    radius=atan2(y_array(1:length)-y_center,x_array(1:length)-x_center);
    degree=radius./pi*180;
    degree(degree&amp;gt;0)=360-degree(degree&amp;gt;0);    % -180~+180=&amp;gt;0~360
    degree(degree&amp;lt;0)=abs(degree(degree&amp;lt;0));
    degree=degree-degree(1);
    degree(degree&amp;gt;0)=360-degree(degree&amp;gt;0);
    degree(degree&amp;lt;0)=-degree(degree&amp;lt;0);
    degree=degree/360;

    x_distance=x_array-x_center;
    y_distance=y_array-y_center;
    distance=zeros(1,length);
    for i=1:length
        distance(i)=norm([x_distance(i),y_distance(i)]);
    end
    min_distance=min(distance);
    norm_distance=distance./min_distance;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This &lt;em&gt;time-series curve&lt;/em&gt; is used to find the positions of &lt;a href=&quot;http://imkaywu.com/2013/11/23/Find-the-fingertips-and-fingerroots.html&quot;&gt;fingertips and fingerroots&lt;/a&gt; to further determine the accurate direction of hand or serve as high-level features for recognition phase. Here are the original and transformed images of a hand gesture.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Original Image&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/original_image.png&quot; alt=&quot;original image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Time-series curve&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/time-series.png&quot; alt=&quot;Time-series curve&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Find the direction of hand</title>
   <link href="http://lhzhang.com/2013/11/23/Find-the-direction-of-hand-gestures.html"/>
   <updated>2013-11-23T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2013/11/23/Find-the-direction-of-hand-gestures</id>
   <content type="html">&lt;p&gt;After detecting the contour of the hand gestures, we need to find the direction(also called as orientation or slope) of the hand in order to make the feature vector we extracted later be rotation invariant.&lt;/p&gt;

&lt;h3&gt;Step 1&lt;/h3&gt;

&lt;p&gt;Intuitively, the contour of hand represent the direction of the hand (though this is not accurate, it's suffice right now), so we can check the neighboring contour vertex and their relative positions, then calculate the direction of hand using this information.&lt;/p&gt;

&lt;p&gt;I decide to predefine 16 different directions and refer to the image for visualization :&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;16 different directions between neighboring contour points&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/16_directions.png&quot; alt=&quot;16_directions&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function direction_angle=direction_detector1(x_array,y_array)
    direction=zeros(1,17);
    for i=1:size(x_array,2);
        index1=i;
        if(i&amp;lt;size(x_array,2)-2)
            index2=i+3;
        elseif(i&amp;lt;size(x_array,2)-1)
            index2=1;
        elseif(i&amp;lt;size(x_array,2))
            index2=2;
        else
            index2=3;
        end
        if(x_array(index2)~=x_array(index1))
            k=(y_array(index2)-y_array(index1))/(x_array(index2)-x_array(index1));
            switch k
                case 0
                    if(x_array(index2)&amp;gt;x_array(index1))
                        direction(1)=direction(1)+1;
                    else
                        direction(17)=direction(17)+1;
                    end
                case -1/3
                    direction(2)=direction(2)+1;
                case -1/2
                    direction(3)=direction(3)+1;
                case -2/3
                    direction(4)=direction(4)+1;
                case -1
                    direction(5)=direction(5)+1;
                case -3/2
                    direction(6)=direction(6)+1;
                case -2
                    direction(7)=direction(7)+1;
                case -3
                    direction(8)=direction(8)+1;

                case 3
                    direction(10)=direction(10)+1;
                case 2
                    direction(11)=direction(11)+1;
                case 3/2
                    direction(12)=direction(12)+1;
                case 1
                    direction(13)=direction(13)+1;
                case 2/3
                    direction(14)=direction(14)+1;
                case 1/2
                    direction(15)=direction(15)+1;
                case 1/3
                    direction(16)=direction(16)+1;
            end
        else
            direction(9)=direction(9)+1;
        end
    end

    angle=-[atan2(0,1),atan2(-1,3),atan2(-1,2),atan2(-2,3),atan2(-1,1),atan2(-3,2),atan2(-2,1),atan2(-3,1),atan2(-1,-0),atan2(-3,-1),atan2(-2,-1),atan2(-3,-2),atan2(-1,-1),atan2(-2,-3),atan2(-1,-2),atan2(-1,-3)]/pi*180;
    direction_temp=zeros(1,15);
    direction([1,17])=[];
    angle(1)=[];
    [a,index]=max(direction);
    for i=1:15
        direction_temp(i)=i-index;
    end
    direction=direction/sum(direction);
    direction=direction.*direction_temp;
    direction=sum(direction);
    index=find(direction_temp==0);
    direction_fix=fix(direction);
    if(direction&amp;lt;0)
        direction_angle=angle(index+direction_fix)-abs(direction-direction_fix)*(angle(index+direction_fix)-angle(index+direction_fix-1));
    else
        direction_angle=abs(direction-direction_fix)*(angle(index+direction_fix+1)-angle(index+direction_fix))+angle(index+direction_fix);
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Step 2&lt;/h3&gt;

&lt;p&gt;This method mentioned above is not all that accurate, especially when the hands are tilted. So I came up with something more accurate. We assume that the direction of the hand can be presented by the overall direction of the stretched fingers. So we first detect the directions of the fingers, then the direction of the hand. Besides, because it's intuitive that the contour points that are below the centroid actually contribute less to the direction of hand, and even worse have nothing to do with the direction(e.g. the contour points in the wrist). So I only use those above the centroid to calculate the directione.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;direction_hand = mean(direction_fingers);&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;First, I need to find out the points that are above the centroid which contribute more to hand direction with the aid of the initially detected hand direction.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function [start_index,end_index]=start_end_points(x_array,y_array,x_center,y_center,direction_angle)
    flag1=1;
    flag2=1;
    direction_angle1=atan2((y_array-y_center),(x_array-x_center))/pi*180;
    direction_angle1(direction_angle1&amp;gt;0)=360-direction_angle1(direction_angle1&amp;gt;0);    % -180~+180=&amp;gt;0~360
    direction_angle1(direction_angle1&amp;lt;0)=-direction_angle1(direction_angle1&amp;lt;0);
    direction_angle2=direction_angle1;
    if(direction_angle&amp;lt;90)
        direction_angle1=direction_angle+270-direction_angle1;%end point,-90+360
    else
        direction_angle1=direction_angle1-direction_angle+90;
    end
    direction_angle2=direction_angle2-direction_angle-90;%start point

    while(true)
        [a,end_index]=min(abs(direction_angle1));
        [a,start_index]=min(abs(direction_angle2));
        if(x_array(end_index)&amp;gt;x_center)
            flag1=0;
        else
            direction_angle1(end_index)=360;
        end
        if(x_array(start_index)&amp;lt;x_center)
            flag2=0;
        else
            direction_angle2(start_index)=360;
        end
        if(~(flag1||flag2))
            break;
        end
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, I transform the hand contour to a &lt;a href=&quot;http://imkaywu.com/2013/11/23/Transform-to-time-series-curve.html&quot;&gt;time-series graph&lt;/a&gt; to &lt;a href=&quot;http://imkaywu.com/2013/11/23/Find-the-fingertips-and-fingerroots.html&quot;&gt;find the fingertip and fingerroots&lt;/a&gt;. These positions of fingertips and fingerroots(two points located at the root of each finger) are the key to find out the accurate positions of each finger, and we assume that the directions of the fingers represent the direction of the hand, thus the direction detected using this method is much more accurate and reliable.&lt;/p&gt;

&lt;p&gt;Here is the code to find the accurate direction of fingers and hand and the image is shown below.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Direction of each finger&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/finger_directions.png&quot; alt=&quot;finger_directions&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%% ----detect the direction again---- %%

function direction_angle=direction_detector3(x_array,y_array,fingertip,fingerroots)
    direction_angle=0;
    for i=1:2
        if(i==1)
            direction_temp=atan2(y_array(fingertip)-y_array(fingerroots(1)),x_array(fingertip)-x_array(fingerroots(1)))/pi*180;
        else
            direction_temp=atan2(y_array(fingertip)-y_array(fingerroots(2)),x_array(fingertip)-x_array(fingerroots(2)))/pi*180;
        end
        direction_temp=(direction_temp&amp;lt;=0)*abs(direction_temp)+(direction_temp&amp;gt;0)*(360-direction_temp);
        direction_temp=(direction_temp&amp;gt;270)*(direction_temp-360)+(direction_temp&amp;lt;270)*direction_temp;
        direction_angle=direction_angle+direction_temp;
    end
    direction_angle=direction_angle/2;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After finding out the accurate direction of the hand, we need to locate the reference point in the image, the reference point is perpendicular to the hand direction. In this way, the degree between the fingertips(or fingerroots) and the reference point relative to the centroid is scale and orientation invariant. This is the key to robust recognition result.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function [x_refer,y_refer,index]=refer_point(x_array,y_array,x_center,y_center,direction_angle)
    direction_angle1=atan2((y_array-y_center),(x_array-x_center))/pi*180;
    direction_angle1(direction_angle1&amp;gt;0)=360-direction_angle1(direction_angle1&amp;gt;0);    % -180~+180=&amp;gt;0~360
    direction_angle1(direction_angle1&amp;lt;0)=-direction_angle1(direction_angle1&amp;lt;0);
    direction_angle1=direction_angle1-direction_angle-180;%this may have problems
    while(true)
        [a,index]=min(abs(direction_angle1));
        x_refer=x_array(index);
        y_refer=y_array(index);
        if(y_refer&amp;gt;y_center)
            break;
        end
        direction_angle1(index)=360;
    end
end
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 
</feed>
