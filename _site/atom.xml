<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>The Journey Is the Reward</title>
 <link href="http://lhzhang.com/atom.xml" rel="self"/>
 <link href="http://lhzhang.com/"/>
 <updated>2014-03-10T23:09:18+08:00</updated>
 <id>http://lhzhang.com/</id>
 <author>
   <name>Linghua Zhang</name>
   <email>linghua.zhang@me.com</email>
 </author>

 
 <entry>
   <title>一些话</title>
   <link href="http://lhzhang.com/2014/03/10/for-parents.html"/>
   <updated>2014-03-10T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/03/10/for-parents</id>
   <content type="html">&lt;p&gt;我承认，现在的局面是我一开始没有料想到的，感觉希望越来越渺茫。我不想推脱责任，我也不会去找借口。但我仍然没有彻底放弃，我还在做着最后的努力。&lt;/p&gt;

&lt;p&gt;老妈问我，为什么不在国内考研，为什么要做这种&lt;strong&gt;完全不可能的事&lt;/strong&gt;。说真的，真正让我伤心的就是这&lt;strong&gt;完全不可能的事&lt;/strong&gt;这几个字。我相信妈妈一定是听了别人胡说八道的东西才会说出这样的话。所以我首先要澄清的就是这&lt;strong&gt;完全不可能的事&lt;/strong&gt;。这绝对不是完全&lt;strong&gt;完全不可能的事&lt;/strong&gt;，我完全可以做得到，只是我不想把5，6年的时间花在一所我不感兴趣的学校，做我不感兴趣的方向。所以我选择的转专业到CS，所以我的选校过于乐观。我很清楚自己在干嘛，我不会啥到往南墙上撞。&lt;/p&gt;

&lt;p&gt;PhD的申请更看重的是申请人的研究经历，这也是我最缺乏的。由于我缺少CS的背景，加上我太晚决定研究方向，让我的研究经历看起来略显单薄。所以这也就是我想如果这次申请失败后要加强的方面。我想全身心投入到手势交互或者计算机视觉的研究中（这就是我现在在清华做的）。&lt;/p&gt;

&lt;p&gt;至于我为什么想去美国，其实我不是想要移民，我也没想去资本主义国家过腐朽的生活，如果谁这么想我的话，那他对美国的PhD难度就太过低估了。我想去美国的原因就是因为我想去硅谷，我想去这个集聚了最多IT界工程师的地方，我想参与到其中去开发最酷的科技（这也是我选择计算机视觉和人机交互的原因，这是未来人类和机器交互最直观可靠的方式）。&lt;/p&gt;

&lt;p&gt;老妈还说我已经23了，但我想说，我现在才23，我还有机会犯错，还有机会补救，我不想用23的年纪，过着33岁时一样小心翼翼的生活。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Blob label and MATLAB implementation</title>
   <link href="http://lhzhang.com/2014/02/24/Blob-label-and-MATLAB-implementation.html"/>
   <updated>2014-02-24T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/02/24/Blob-label-and-MATLAB-implementation</id>
   <content type="html">&lt;h2&gt;Graphical example of the algorithm&lt;/h2&gt;

&lt;h3&gt;The array from which connected regions are to be extracted is given below (8-connectivity based).&lt;/h3&gt;

&lt;p&gt;We first assign different binary values to elements in the graph. Attention should be paid that the &quot;0~1&quot; values write on the center of the elements in the following graph are elements' values. While, the &quot;1,2,...,7&quot; values in the next two graphs are the elements' labels. The two concepts should not be confused.
&lt;img src=&quot;/media/images/blob%20label%201.png&quot; alt=&quot;blob label 1&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;After the first pass, the following labels are generated. A total of 7 labels are generated in accordance with the conditions highlighted above.&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/blob%20label%202.png&quot; alt=&quot;blob label 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The label equivalence relationships generated are,
&lt;img src=&quot;/media/images/blob%20label%203.png&quot; alt=&quot;blob label 3&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;Array generated after the merging of labels is carried out. Here, the label value that was the smallest for a given region &quot;floods&quot; throughout the connected region and gives two distinct labels, and hence two distinct labels.&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/blob%20label%204.png&quot; alt=&quot;blob label 4&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;Final result in color to clearly see two different regions that have been found in the array.&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/blob%20label%205.png&quot; alt=&quot;blob label 5&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;Source Code&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;function label_map = blob_detector( binary_map )
    [ y , x ] = find( binary_map == 1 );
    y_start = min( y );
    y_end = max( y );
    x_end = max( x );
    label_map = zeros( size( binary_map ) );
    label = 1;
    addRow = 0;
    addCol = 0;
    if( y_end == size( binary_map , 1 ) )
        label_map( y_end + 1 , : ) = 0;
        addRow = 1;
    end
    if( x_end == size( binary_map , 2 ) )
        label_map( : , x_end + 1 ) = 0;
        addCol = 1;
    end
    % blob label
    for i = y_start : y_end
        for j = find( binary_map( i ,: ) , 1 ) : find( binary_map( i ,: ) , 1 , 'last' )
            if( binary_map( i , j ) &amp;gt; 0 )
                label_neighbor = label_map( i - 1 : i + 1 , j - 1 : j + 1 );
                if( sum( sum( label_neighbor ) ) == 0 )
                    label_map( i , j ) = label( end );
                    label = [ label , label(end)+1 ];
                else
                    label_temp = unique( label_neighbor( label_neighbor &amp;gt; 0 ) );
                    label_map( i , j ) =label_temp( 1 );
                    if( size( label_temp , 1 ) &amp;gt; 1 )
                        label_temp = label_temp( 2 : end );
                        label( label_temp( label( label_temp ) &amp;gt; label_map( i , j ) ) ) = label_map( i , j );
                    end
                end
            end
        end
    end
    % combine labels
    if( addRow )
        label_map( end , : ) = [];
    end
    if( addCol )
        label_map( : , end ) = [];
    end
    label = label( 1 : end - 1 );
    for i = 1 : size( label , 2 )
        while( 1 )
            if( label( label( i ) ) == label( i ) )
                break;
            else
                label( i ) = label( label( i ) );
            end
        end
    end

    for i = 1 : size(label , 2 )
        label_map( label_map == i ) = label( i );
    end
    % find the dominant blob
    label_temp = unique( label );
    blob_max = 0;
    for i = 1 : size(label_temp , 2)
        if( blob_max &amp;lt; sum( sum( label_map == label_temp( i ) ) ) )
            blob_max = sum( sum( label_map == label_temp( i ) ) );
            label = label_temp( i );
        end
    end

    label_map( label_map ~= label ) = 0;
    label_map( label_map == label ) = 1;
end
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>An Introduction to Deformable Part Model</title>
   <link href="http://lhzhang.com/2014/02/05/a-introduction-to-deformable-part-model.html"/>
   <updated>2014-02-05T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/02/05/a-introduction-to-deformable-part-model</id>
   <content type="html">&lt;p&gt;Deformable Part Model是最近两年最为流行的图像中物体检测模型，利用这个模型的方法在近几届PASCAL VOC Challenge中都取得了较好的效果。其作者，Brown University的&lt;a href=&quot;http://cs.brown.edu/~pff/&quot;&gt;Pedro Felzenszwalb&lt;/a&gt;教授，也因为这项成就获得了VOC组委会授予的终身成就奖。有人认为这个模型是目前最好的物体检测算法。&lt;/p&gt;

&lt;p&gt;不同于bag of features和hog模板匹配，这类“object conceptually weaker”的模型，在Deformable Part Model中，通过描述每一部分和部分间的位置关系来表示物体（part+deformable configuration）。其实早在1973年，Part Model就已经在 &quot;The representation and matching of pictorial structures&quot; 这篇文章中被提出了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;part model&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/deformable%20part%20model.jpg&quot; alt=&quot;part model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Part Model中，我们通过描述a collection of parts以及connection between parts来表示物体。图1表示经典的弹簧模型，物体的每一部分通过弹簧连接。我们定义一个energy function，该函数度量了两部分之和：每一部分的匹配程度，部分间连接的变化程度（可以想象为弹簧的形变量）。与模型匹配最好的图像就是能使这个energy function最小的图片。形式化表示中，我们可以用一无向图 G=(V,E) 来表示物体的模型，V={v1,...,vn} 代表n个部分，边 (vi,vj)∈E 代表两部分间的连接。物体的某个实例的configuration可以表示为 L=(l1,...,ln)，li 表示为 vi 的位置（可以简单的将图片的configuration理解为各部分的位置布局，实际configuration可以包含part的其他属性）。给定一幅图像，用 mi(li) 来度量 vi 被放置图片中的 li 位置时，与模板的不匹配程度；用 dij(li,lj) 度量 vi,vj 被分别放置在图片中的 li,lj 位置时，模型的变化程度。因此，一副图像相对于模型的最优configuration，就是既能使每一部分匹配的好，又能使部分间的相对关系与模型尽可能的相符的那一个。同样的，模型也自然要描述这两部分。可以通过下面的公式描述最优configuration：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/formular_DPM.png&quot; alt=&quot;formular DPM&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pedro Felzenszwalb教授提出的Deformable Part Model用到了三方面的知识：1.Hog Features 2.Part Model 3. Latent SVM。&lt;/p&gt;

&lt;p&gt;作者通过Hog特征模板来刻画每一部分，然后进行匹配。并且采用了金字塔，即在不同的分辨率上提取Hog特征
利用上段提出的Part Model。在进行object detection时，detect window的得分等于part的匹配得分减去模型变化的花费。
在训练模型时，需要训练得到每一个part的Hog模板，以及衡量part位置分布cost的参数。文章中提出了Latent SVM方法，将deformable part model的学习问题转换为一个分类问题。利用SVM学习，将part的位置分布作为latent values，模型的参数转化为SVM的分割超平面。具体实现中，作者采用了迭代计算的方法，不断地更新模型。
作者的页面上有模型的matlab实现源码，必须运行在linux或mac平台中。另外，源码中已经包含PASCAL VOC中各个类别训练好的模型，可以直接用，如果需要自己训练模型，这个过程是很耗时的。为了提高效率，作者又在2010年的“Cascade Object Detection with Deformable Part Models”这篇文章中对part model做了改进，将效率提高了20倍左右。&lt;/p&gt;

&lt;p&gt;相关资料：&lt;/p&gt;

&lt;p&gt;Fischler, M.A. and Elschlager, R.A. The representation and matching of pictorial structures, 1973&lt;/p&gt;

&lt;p&gt;Felzenszwalb, P.F. and Huttenlocher, D.P. Pictorial structures for object recognition,2005&lt;/p&gt;

&lt;p&gt;http://people.csail.mit.edu/torralba/courses/6.870/slide/6870_2008-09-10_histograms_pinto_opt.pdf&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Image Process and Computer Vision - foundation, classic and recent facts(图像处理与计算机视觉：基础，经典以及最近发展)</title>
   <link href="http://lhzhang.com/2014/02/05/A-Introduction-to-Image-Process-and-Computer-Vision.html"/>
   <updated>2014-02-05T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/02/05/A-Introduction-to-Image-Process-and-Computer-Vision</id>
   <content type="html">&lt;h2&gt;本文的特点和结构，以及适合的对象&lt;/h2&gt;

&lt;p&gt;本文的安排如下。第一部分是绪论。第二部分是图像处理中所需要用到的理论基础，主要是这个领域所涉及到的一些比较好的参考书籍。第三部分是计算机视觉中所涉及到的信号处理和模式识别文章。由于图像处理与图像分析太难区分了，第四部分集中讨论了它们。第五部分是计算机视觉部分。最后是小结。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/dcraw/article/details/7617891&quot;&gt;原文链接&lt;/a&gt;,在此感谢原文作者的分享精神。&lt;/p&gt;

&lt;h2&gt;图像处理与计算机视觉：基础，经典以及最近发展（1）序&lt;/h2&gt;

&lt;h3&gt;图像处理和计算机视觉的分类&lt;/h3&gt;

&lt;p&gt;按照当前流行的分类方法，可以分为以下三部分：&lt;/p&gt;

&lt;p&gt;图像处理：对输入的图像做某种变换，输出仍然是图像，基本不涉及或者很少涉及图像内容的分析。比较典型的有图像变换，图像增强，图像去噪，图像压缩，图像恢复，二值图像处理等等。基于阈值的图像分割也属于图像处理的范畴。一般处理的是单幅图像。&lt;/p&gt;

&lt;p&gt;图像分析：对图像的内容进行分析，提取有意义的特征，以便于后续的处理。处理的仍然是单幅图像。&lt;/p&gt;

&lt;p&gt;计算机视觉：对图像分析得到的特征进行分析，提取场景的语义表示，让计算机具有人眼和人脑的能力。这时处理的是多幅图像或者序列图像，当然也包括部分单幅图像。&lt;/p&gt;

&lt;p&gt;关于图像处理，图像分析和计算机视觉的划分并没有一个很统一的标准。一般的来说，图像处理的书籍总会或多或少的介绍一些图像分析和计算机视觉的知识，比如冈萨雷斯的数字图像处理。而计算机视觉的书籍基本上都会包括图像处理和图像分析，只是不会介绍的太详细。其实图像处理，图像分析和计算机视觉都可以纳入到计算机视觉的范畴：图像处理-&gt;低层视觉（low level vision），图像分析-&gt;中间层视觉（middle level vision），计算机视觉-&gt;高层视觉（high level vision）。这是一般的计算机视觉或者机器视觉的划分方法。在本文中，仍然按照传统的方法把这个领域划分为图像处理，图像分析和计算机视觉。&lt;/p&gt;

&lt;h3&gt;图像处理和计算机视觉开源库以及编程语言选择&lt;/h3&gt;

&lt;p&gt;目前在图像处理中有两种最重要的语言：c/c++和matlab。它们各有优点：c/c++比较适合大型的工程，效率较高，而且容易转成硬件语言，是工业界的默认语言之一。而matlab实现起来比较方便，适用于算法的快速验证，而且matlab有成熟的工具箱可以使用，比如图像处理工具箱，信号处理工具箱。它们有一个共同的特点：开源的资源非常多。在学术界matlab使用的非常多，很多作者给出的源代码都是matlab版本。最近由于OpenCV的兴起和不断完善，c/c++在图像处理中的作用越来越大。总的来说，c/c++和matlab都必须掌握，最好是精通，当然侧重在c/c++上对找工作会有很大帮助。&lt;/p&gt;

&lt;h3&gt;至于开源库，个人非常推荐OpenCV，主要有以下原因：&lt;/h3&gt;

&lt;p&gt;（1）简单易入手。opencv进入opencv2.x的时代后，使用起来越来越简单,接口越来越傻瓜化，越来越matlab化。只要会imread,imwrite,imshow和了解Mat的基本操作就可以开始入手了。
（2）Opencv有一堆图像处理和计算机视觉的大牛在维护，bug在逐步减少，每个新的版本都会带来不同的惊喜。而且它已经或者逐步在移植到不同的平台,并提供了对Python的很好的支持。
（3）在Opencv上可以尝试各种最新以及成熟的技术，而不需要自己从头去写，比如人脸检测（Harr，LBP），DPM（Latent SVM），高斯背景模型，特征检测，聚类，hough变换等等。而且它还支持各种机器学习方法（SVM，NN，KNN，决策树，Boosting等），使用起来很简单。
（4）文档内容丰富，并且给出了很多示例程序。当然也有一些地方文档描述不清楚，不过看看代码就很清楚了。
（5）完全开源。可以从中间抠出任何需要的算法。
（6）从学校出来后，除极少数会继续在学术圈里，大部分还是要进入工业界。现在在工业界，c/c++仍是主流，很多公司都会优先考虑熟悉或者精通opencv的。事实上，在学术界，现在opencv也大有取代matlab之势。以前的demo或者source code，很多作者都愿意给出matlab版本的，然后别人再呼哧呼哧改成c版本的。现在作者干脆给出c/c++版本，或者自己集成到opencv中去，这样能快速提升自己的影响力。&lt;/p&gt;

&lt;p&gt;如果想在图像处理和计算机视觉界有比较深入的研究，并且以后打算进入这个领域工作的话，建议把OpenCV作为自己的主攻方向。如果找工作的时候敢号称自己精通OpenCV的话，肯定可以找到一份满意的工作。&lt;/p&gt;

&lt;h2&gt;图像处理与计算机视觉：基础，经典以及最近发展（2）图像处理与计算机视觉相关的书籍&lt;/h2&gt;

&lt;p&gt;Last update: 2012-6-23
1. 数学
我们所说的图像处理实际上就是数字图像处理，是把真实世界中的连续三维随机信号投影到传感器的二维平面上，采样并量化后得到二维矩阵。数字图像处理就是二维矩阵的处理，而从二维图像中恢复出三维场景就是计算机视觉的主要任务之一。这里面就涉及到了图像处理所涉及到的三个重要属性：连续性，二维矩阵，随机性。所对应的数学知识是高等数学（微积分），线性代数（矩阵论），概率论和随机过程。这三门课也是考研的三门课，构成了图像处理和计算机视觉最基础的数学基础。如果想要更进一步，就要到网上搜搜林达华推荐的数学数目了。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;信号处理
图像处理其实就是二维和三维信号处理，而处理的信号又有一定的随机性，因此经典信号处理和随机信号处理都是图像处理和计算机视觉中必备的理论基础。&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;2.1经典信号处理
信号与系统(第2版)  Alan V.Oppenheim等著 刘树棠译
离散时间信号处理(第2版)  A.V.奥本海姆等著 刘树棠译
数字信号处理:理论算法与实现胡广书 (编者)&lt;/p&gt;

&lt;p&gt;2.2随机信号处理
现代信号处理 张贤达著
统计信号处理基础:估计与检测理论Steven M.Kay等著 罗鹏飞等译
自适应滤波器原理(第4版) Simon Haykin著 郑宝玉等译&lt;/p&gt;

&lt;p&gt;2.3 小波变换
信号处理的小波导引:稀疏方法(原书第3版)  tephane Malla著, 戴道清等译&lt;/p&gt;

&lt;p&gt;2.4 信息论
信息论基础(原书第2版) Thomas M.Cover等著 阮吉寿等译&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;模式识别
Pattern Recognition and Machine Learning Bishop, Christopher M. Springer
模式识别(英文版)(第4版) 西奥多里德斯著
Pattern Classification (2nd Edition) Richard O. Duda等著
Statistical Pattern Recognition, 3rd Edition Andrew R. Webb等著
模式识别(第3版) 张学工著&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;图像处理与计算机视觉的书籍推荐
图像处理，分析与机器视觉 第三版Sonka等著 艾海舟等译
Image Processing, Analysis and Machine Vision
这本书是图像处理与计算机视觉里面比较全的一本书了，几乎涵盖了图像视觉领域的各个方面。中文版的个人感觉也还可以，值得一看。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;数字图像处理 第三版 冈萨雷斯等著
Digital Image Processing
数字图像处理永远的经典，现在已经出到了第三版，相当给力。我的导师曾经说过，这本书写的很优美，对写英文论文也很有帮助，建议购买英文版的。&lt;/p&gt;

&lt;p&gt;计算机视觉：理论与算法 RichardSzeliski著
Computer Vision: Theory and Algorithm
微软的Szeliski写的一本最新的计算机视觉著作。内容非常丰富，尤其包括了作者的研究兴趣，比如一般的书里面都没有的Image Stitching和Image Matting等。这也从另一个侧面说明这本书的通用性不如Sonka的那本。不过作者开放了这本书的电子版，可以有选择性的阅读。&lt;/p&gt;

&lt;p&gt;Multiple View Geometry in Computer Vision 第二版Harley等著
引用达一万多次的经典书籍了。第二版到处都有电子版的。第一版曾出过中文版的，后来绝版了。网上也可以找到电子版。&lt;/p&gt;

&lt;p&gt;计算机视觉：一种现代方法 DAForsyth等著
Computer Vision: A Modern Approach
MIT的经典教材。虽然已经过去十年了，还是值得一读。第二版已经在今年（2012年）出来了，在iask上可以找到非常清晰的版本，将近800页，补充了很多内容。期待影印版。&lt;/p&gt;

&lt;p&gt;Machine vision: theory,algorithms, practicalities 第三版 Davies著
为数不多的英国人写的书，偏向于工业。&lt;/p&gt;

&lt;p&gt;数字图像处理 第四版 Pratt著
Digital Image Processing
写作风格独树一帜，也是图像处理领域很不错的一本书。网上也可以找到非常清晰的电子版。&lt;/p&gt;

&lt;p&gt;5 小结&lt;/p&gt;

&lt;p&gt;罗嗦了这么多，实际上就是几个建议：
（1）基础书千万不可以扔，也不能低价处理给同学或者师弟师妹。不然到时候还得一本本从书店再买回来的。钱是一方面的问题，对着全新的书看完全没有看自己当年上过的课本有感觉。
（2）遇到有相关的课，果断选修或者蹭之，比如随机过程，小波分析，模式识别，机器学习，数据挖掘，现代信号处理甚至泛函。多一些理论积累对将来科研和工作都有好处。
（3）资金允许的话可以多囤一些经典的书，有的时候从牙缝里面省一点都可以买一本好书。不过千万不要像我一样只囤不看。&lt;/p&gt;

&lt;h2&gt;图像处理与计算机视觉：基础，经典以及最近发展（3）计算机视觉中的信号处理与模式识别&lt;/h2&gt;

&lt;p&gt;Last Update: 2012-6-23&lt;/p&gt;

&lt;p&gt;从本章开始，进入本文的核心章节。一共分三章，分别讲述信号处理与模式识别，图像处理与分析以及计算机视觉。与其说是讲述，不如说是一些经典文章的罗列以及自己的简单点评。与前一个版本不同的是，这次把所有的文章按类别归了类，并且增加了很多文献。分类的时候并没有按照传统的分类方法，而是划分成了一个个小的门类，比如SIFT，Harris都作为了单独的一类，虽然它们都可以划分到特征提取里面去。这样做的目的是希望能突出这些比较实用且比较流行的方法。为了以后维护的方法，按照字母顺序排的序。
本章的下载地址在：
http://iask.sina.com.cn/u/2252291285/ish?folderid=868770&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Boosting&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Boosting是最近十来年来最成功的一种模式识别方法之一，个人认为可以和SVM并称为模式识别双子星。它真正实现了“三个臭皮匠，赛过诸葛亮”。只要保证每个基本分类器的正确率超过50%，就可以实现组合成任意精度的分类器。这样就可以使用最简单的线性分类器。Boosting在计算机视觉中的最成功的应用无疑就是Viola-Jones提出的基于Haar特征的人脸检测方案。听起来似乎不可思议，但Haar+Adaboost确实在人脸检测上取得了巨大的成功，已经成了工业界的事实标准，并且逐步推广到其他物体的检测。
Rainer Lienhart在2002 ICIP发表的这篇文章是Haar+Adaboost的最好的扩展，他把原始的两个方向的Haar特征扩展到了四个方向，他本人是OpenCV积极的参与着。现在OpenCV的库里面实现的Cascade Classification就包含了他的方法。这也说明了盛会（如ICIP，ICPR，ICASSP）也有好文章啊，只要用心去发掘。&lt;/p&gt;

&lt;p&gt;[1997] A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting
[1998] Boosting the margin A new explanation for the effectiveness of voting methods
[2002 ICIP TR] Empirical Analysis of Detection Cascades of Boosted Classifiers for Rapid ObjectDetection
[2003] The Boosting Approach to Machine Learning An Overview
[2004 IJCV] Robust Real-time Face Detection&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Clustering&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;聚类主要有K均值聚类，谱聚类和模糊聚类。在聚类的时候如果自动确定聚类中心的数目是一个一直没有解决的问题。不过这也很正常，评价标准不同，得到的聚类中心数目也不一样。不过这方面还是有一些可以参考的文献，在使用的时候可以基于这些方法设计自己的准则。关于聚类，一般的模式识别书籍都介绍的比较详细，不过关于cluster validity讲的比较少，可以参考下面的文章看看。&lt;/p&gt;

&lt;p&gt;[1989 PAMI] Unsupervised Optimal Fuzzy Clustering
[1991 PAMI] A validity measure for fuzzy clustering
[1995 PAMI] On cluster validity for the fuzzy c-means model
[1998] Some New Indexes of Cluster Validity
[1999 ACM] Data Clustering A Review
[1999 JIIS] On Clustering Validation Techniques
[2001] Estimating the number of clusters in a dataset via the Gap statistic&lt;/p&gt;

&lt;p&gt;[2001 NIPS] On Spectral Clustering&lt;/p&gt;

&lt;p&gt;[2002] A stability based method for discovering structure in clustered data&lt;/p&gt;

&lt;p&gt;[2007] A tutorial on spectral clustering&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Compressive Sensing&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;最近大红大紫的压缩感知理论。&lt;/p&gt;

&lt;p&gt;[2006 TIT] Compressed Sensing
[2008 SPM] An Introduction to Compressive Sampling
[2011 TSP] Structured Compressed Sensing From Theory to Applications&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Decision Trees&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;对决策树感兴趣的同学这篇文章是非看不可的了。&lt;/p&gt;

&lt;p&gt;[1986] Introduction to Decision Trees&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Dynamical Programming&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;动态规划也是一个比较使用的方法，这里挑选了一篇PAMI的文章以及一篇Book Chapter&lt;/p&gt;

&lt;p&gt;[1990 PAMI] using dynamic programming for solving variational problems in vision
[Book Chapter] Dynamic Programming&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Expectation Maximization&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;EM是计算机视觉中非常常见的一种方法，尤其是对参数的估计和拟合，比如高斯混合模型。EM和GMM在Bishop的PRML里单独的作为一章，讲的很不错。关于EM的tutorial，网上也可以搜到很多。&lt;/p&gt;

&lt;p&gt;[1977] Maximum likelihood from incomplete data via the EM algorithm
[1996 SPM] The Expectation-Maximzation Algorithm&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Graphical Models&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;伯克利的乔丹大仙的Graphical Model，可以配合这Bishop的PRML一起看。&lt;/p&gt;

&lt;p&gt;[1999 ML] An Introduction to Variational Methods for Graphical Models&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Hidden Markov Model&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;HMM在语音识别中发挥着巨大的作用。在信号处理和图像处理中也有一定的应用。最早接触它是跟小波和检索相关的，用HMM来描述小波系数之间的相互关系，并用来做检索。这里提供一篇1989年的经典综述，几篇HMM在小波，分割，检索和纹理上的应用以及一本比较早的中文电子书，现在也不知道作者是谁，在这里对作者表示感谢。&lt;/p&gt;

&lt;p&gt;[1989 ] A tutorial on hidden markov models and selected applications in speech recognition
[1998 TSP] Wavelet-based statistical signal processing using hidden Markov models
[2001 TIP] Multiscale image segmentation using wavelet-domain hidden Markov models
[2002 TMM] Rotation invariant texture characterization and retrieval using steerable wavelet-domain hiddenMarkov models
[2003 TIP] Wavelet-based texture analysis and synthesis using hidden Markov models
Hmm Chinese book.pdf&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Independent Component Analysis&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;同PCA一样，独立成分分析在计算机视觉中也发挥着重要的作用。这里介绍两篇综述性的文章，最后一篇是第二篇的TR版本，内容差不多，但比较清楚一些。&lt;/p&gt;

&lt;p&gt;[1999] Independent Component Analysis A Tutorial
[2000 NN] Independent component analysis algorithms and applications
[2000] Independent Component Analysis Algorithms and Applications&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Information Theory&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;计算机视觉中的信息论。这方面有一本很不错的书Information Theory in Computer Vision and Pattern Recognition。这本书有电子版，如果需要用到的话，也可以参考这本书。&lt;/p&gt;

&lt;p&gt;[1995 NC] An Information-Maximization Approach to Blind Separation and Blind Deconvolution
[2010] An information theory perspective on computational vision&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Kalman Filter&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;这个话题在张贤达老师的现代信号处理里面讲的比较深入，还给出了一个有趣的例子。这里列出了Kalman的最早的论文以及几篇综述，还有Unscented Kalman Filter。同时也有一篇Kalman Filter在跟踪中的应用以及两本电子书。&lt;/p&gt;

&lt;p&gt;[1960 Kalman] A New Approach to Linear Filtering and Prediction Problems Kalman
[1970] Least-squares estimation_from Gauss to Kalman
[1997 SPIE] A New Extension of the Kalman Filter to Nonlinear System
[2000] The Unscented Kalman Filter for Nonlinear Estimation
[2001 Siggraph] An Introduction to the Kalman Filter_full
[2003] A Study of the Kalman Filter applied to Visual Tracking&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Pattern Recognition and Machine Learning&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;模式识别名气比较大的几篇综述&lt;/p&gt;

&lt;p&gt;[2000 PAMI] Statistical pattern recognition a review
[2004 CSVT] An Introduction to Biometric Recognition
[2010 SPM] Machine Learning in Medical Imaging&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Principal Component Analysis&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;著名的PCA，在特征的表示和特征降维上非常有用。&lt;/p&gt;

&lt;p&gt;[2001 PAMI] PCA versus LDA
[2001] Nonlinear component analysisas a kernel eigenvalue problem
[2002] A Tutorial on Principal Component Analysis
[2004 PAMI] Two-dimensional PCA a new approach to appearance-based face representation and recognition&lt;/p&gt;

&lt;p&gt;[2009] A Tutorial on Principal Component Analysis
[2011] Robust Principal Component Analysis
[Book Chapter] Singular Value Decomposition and Principal Component Analysis&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Random Forest&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;随机森林&lt;/p&gt;

&lt;p&gt;[2001 ML] Random Forests&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;RANSAC&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;随机抽样一致性方法，与传统的最小均方误差等完全是两个路子。在Sonka的书里面也有提到。&lt;/p&gt;

&lt;p&gt;[2009 BMVC] Performance Evaluation of RANSAC Family&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Singular Value Decomposition
对于非方阵来说，就是SVD发挥作用的时刻了。一般的模式识别书都会介绍到SVD。这里列出了K-SVD以及一篇BookChapter
[2006 TSP] K-SVD An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation
[Book Chapter] Singular Value Decomposition and Principal Component Analysis&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Sparse Representation&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;这里主要是Proceeding of IEEE上的几篇文章&lt;/p&gt;

&lt;p&gt;[2009 PAMI] Robust Face Recognition via Sparse Representation
[2009 PIEEE] Image Decomposition and Separation Using Sparse Representations An Overview
[2010 PIEEE] Dictionaries for Sparse Representation Modeling
[2010 PIEEE] It's All About the Data
[2010 PIEEE] Matrix Completion With Noise
[2010 PIEEE] On the Role of Sparse and Redundant Representations in Image Processing
[2010 PIEEE] Sparse Representation for Computer Vision and Pattern Recognition
[2011 SPM] Directionary Learning&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Support Vector Machines&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;[1998] A Tutorial on Support Vector Machines for Pattern Recognition
[2004] LIBSVM A Library for Support Vector Machines&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Wavelet&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;在小波变换之前，时频分析的工具只有傅立叶变换。众所周知，傅立叶变换在时域没有分辨率，不能捕捉局部频域信息。虽然短时傅立叶变换克服了这个缺点，但只能刻画恒定窗口的频率特性，并且不能很好的扩展到二维。小波变换的出现很好的解决了时频分析的问题，作为一种多分辨率分析工具，在图像处理中得到了极大的发展和应用。在小波变换的发展过程中，有几个人是不得不提的，Mallat， Daubechies，Vetteri， M.N.Do， Swelden，Donoho。Mallat和Daubechies奠定了第一代小波的框架，他们的著作更是小波变换的必读之作，相对来说，小波十讲太偏数学了，比较难懂。而Mallat的信号处理的小波导引更偏应用一点。Swelden提出了第二代小波，使小波变换能够快速方便的实现，他的功劳有点类似于FFT。而Donoho，Vetteri，Mallat及其学生们提出了Ridgelet, Curvelet, Bandelet,Contourlet等几何小波变换，让小波变换有了方向性，更便于压缩，去噪等任务。尤其要提的是M.N.Do，他是一个越南人，得过IMO的银牌，在这个领域著作颇丰。我们国家每年都有5个左右的IMO金牌，希望也有一两个进入这个领域，能够也让我等也敬仰一下。而不是一股脑的都进入金融，管理这种跟数学没有多大关系的行业，呵呵。很希望能看到中国的陶哲轩，中国的M.N.Do。&lt;/p&gt;

&lt;p&gt;说到小波，就不得不提JPEG2000。在JPEG2000中使用了Swelden和Daubechies提出的用提升算法实现的9/7小波和5/3小波。如果对比JPEG和JPEG2000，就会发现JPEG2000比JPEG在性能方面有太多的提升。本来我以为JPEG2000的普及只是时间的问题。但现在看来，这个想法太Naive了。现在已经过去十几年了，JPEG2000依然没有任何出头的迹象。不得不说，工业界的惯性力量太强大了。如果以前的东西没有什么硬伤的话，想改变太难了。不巧的是，JPEG2000的种种优点在最近的硬件上已经有了很大的提升。压缩率？现在动辄1T，2T的硬盘，没人太在意压缩率。渐进传输？现在的网速包括无线传输的速度已经相当快了，渐进传输也不是什么优势。感觉现在做图像压缩越来越没有前途了，从最近的会议和期刊文档也可以看出这个趋势。不管怎么说，JPEG2000的Overview还是可以看看的。&lt;/p&gt;

&lt;p&gt;[1989 PAMI] A theory for multiresolution signal decomposition&lt;em&gt;&lt;em&gt;the wavelet representation
[1996 PAMI] Image Representation using 2D Gabor Wavelet
[1998 ] FACTORING WAVELET TRANSFORMSIN TO LIFTING STEPS
[1998] The Lifting Scheme&lt;/em&gt; A Construction Of Second Generation Wavelets
[2000 TCE] The JPEG2000 still image coding system&lt;/em&gt; an overview
[2002 TIP] The curvelet transform for image denoising
[2003 TIP] Gray and color imagecontrast enhancement by the curvelet transform
[2003 TIP] Mathematical Properties of the jpeg2000 wavelet filters
[2003 TIP] The finite ridgelet transform for image representation
[2005 TIP] Sparse Geometric Image Representations With Bandelets
[2005 TIP] The Contourlet Transform_ An Efficient Directional Multiresolution Image Representation
[2010 SPM] The Curvelet Transform&lt;/p&gt;

&lt;h2&gt;图像处理与计算机视觉：基础，经典以及最近发展（4）图像处理与分析&lt;/h2&gt;

&lt;p&gt;Last update: 2012-6-3&lt;/p&gt;

&lt;p&gt;本章主要讨论图像处理与分析。虽然后面计算机视觉部分的有些内容比如特征提取等也可以归结到图像分析中来，但鉴于它们与计算机视觉的紧密联系，以及它们的出处，没有把它们纳入到图像处理与分析中来。同样，这里面也有一些也可以划归到计算机视觉中去。这都不重要，只要知道有这么个方法，能为自己所用，或者从中得到灵感，这就够了。
本章的下载地址在：
http://iask.sina.com.cn/u/2252291285/ish?folderid=868771&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Bilateral Filter&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Bilateral Filter俗称双边滤波器是一种简单实用的具有保持边缘作用的平缓滤波器，由Tomasi等在1998年提出。它现在已经发挥着重大作用，尤其是在HDR领域。
[1998 ICCV] BilateralFiltering for Gray and Color Images
[2008 TIP] AdaptiveBilateral Filter for Sharpness Enhancement and Noise Removal&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Color&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;如果对颜色的形成有一定的了解，能比较深刻的理解一些算法。这方面推荐冈萨雷斯的数字图像处理中的相关章节以及Sharma在Digital Color Imaging Handbook中的第一章“Colorfundamentals for digital imaging”。跟颜色相关的知识包括Gamma，颜色空间转换，颜色索引以及肤色模型等，这其中也包括著名的EMD。
[1991 IJCV] Color Indexing
[2000 IJCV] The EarthMover's Distance as a Metric for Image Retrieval
[2001 PAMI] Colorinvariance
[2002 IJCV] StatisticalColor Models with Application to Skin Detection
[2003] A review of RGBcolor spaces
[2007 PR]A survey ofskin-color modeling and detection methods
Gamma.pdf
GammaFAQ.pdf&lt;/p&gt;

&lt;p&gt;3.Compression and Encoding&lt;/p&gt;

&lt;p&gt;个人以为图像压缩编码并不是当前很热的一个话题，原因前面已经提到过。这里可以看看一篇对编码方面的展望文章
[2005 IEEE] Trends andperspectives in image and video coding&lt;/p&gt;

&lt;p&gt;4.Contrast Enhancement&lt;/p&gt;

&lt;p&gt;对比度增强一直是图像处理中的一个恒久话题，一般来说都是基于直方图的，比如直方图均衡化。冈萨雷斯的书里面对这个话题讲的比较透彻。这里推荐几篇个人认为不错的文章。
[2002 IJCV] Vision and theAtmosphere
[2003 TIP] Gray and colorimage contrast enhancement by the curvelet transform
[2006 TIP] Gray-levelgrouping (GLG) an automatic method for optimized image contrastenhancement-part II
[2006 TIP] Gray-levelgrouping (GLG) an automatic method for optimized image contrastEnhancement-part I
[2007 TIP] TransformCoefficient Histogram-Based Image Enhancement Algorithms Using Contrast Entropy
[2009 TIP] A HistogramModification Framework and Its Application for Image Contrast Enhancement&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Deblur (Restoration)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;图像恢复或者图像去模糊一直是一个非常难的问题，尤其是盲图像恢复。港中文的jiaya jia老师在这方面做的不错，他在主页也给出了exe。这方面的内容也建议看冈萨雷斯的书。这里列出了几篇口碑比较好的文献，包括古老的Richardson-Lucy方法，几篇盲图像恢复的综述以及最近的几篇文章，尤以Fergus和Jiaya Jia的为经典。
[1972] Bayesian-BasedIterative Method of Image Restoration
[1974] an iterative techniquefor the rectification of observed distributions
[1990 IEEE] Iterativemethods for image deblurring
[1996 SPM] Blind ImageDeconvolution
[1997 SPM] Digital imagerestoration
[2005] Digital ImageReconstruction - Deblurring and Denoising
[2006 Siggraph] RemovingCamera Shake from a Single Photograph
[2008 Siggraph]High-quality Motion Deblurring from a Single Image
[2011 PAMI]Richardson-Lucy Deblurring for Scenes under a Projective Motion Path&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Dehazing and Defog&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;严格来说去雾化也算是图像对比度增强的一种。这方面最近比较好的工作就是He kaiming等提出的Dark Channel方法。这篇论文也获得了2009的CVPR 最佳论文奖。2003年的广东高考状元已经于2011年从港中文博士毕业加入MSRA（估计当时也就二十五六岁吧），相当了不起。
[2008 Siggraph] SingleImage Dehazing
[2009 CVPR] Single ImageHaze Removal Using Dark Channel Prior
[2011 PAMI] Single ImageHaze Removal Using Dark Channel Prior&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Denoising&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;图像去噪也是图像处理中的一个经典问题，在数码摄影中尤其重要。主要的方法有基于小波的方法和基于偏微分方程的方法。
[1992 SIAM] Imageselective smoothing and edge detection by nonlinear diffusion. II
[1992 SIAM] Imageselective smoothing and edge detection by nonlinear diffusion
[1992] Nonlinear totalvariation based noise removal algorithms
[1994 SIAM] Signal andimage restoration using shock filters and anisotropic diffusion
[1995 TIT] De-noising bysoft-thresholding
[1998 TIP] Orientationdiffusions
[2000 TIP] Adaptivewavelet thresholding for image denoising and compression
[2000 TIP] Fourth-orderpartial differential equations for noise removal
[2001] Denoising  through wavelet shrinkage
[2002 TIP] The CurveletTransform for Image Denoising
[2003 TIP] Noise removalusing fourth-order partial differential equation with applications to medicalmagnetic resonance images in space and time
[2008 PAMI] AutomaticEstimation and Removal of Noise from a Single Image
[2009 TIP] Is DenoisingDead&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Edge Detection&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;边缘检测也是图像处理中的一个基本任务。传统的边缘检测方法有基于梯度算子，尤其是Sobel算子，以及经典的Canny边缘检测。到现在，Canny边缘检测及其思想仍在广泛使用。关于Canny算法的具体细节可以在Sonka的书以及canny自己的论文中找到，网上也可以搜到。最快最直接的方法就是看OpenCV的源代码，非常好懂。在边缘检测方面，Berkeley的大牛J Malik和他的学生在2004年的PAMI提出的方法效果非常好，当然也比较复杂。在复杂度要求不高的情况下，还是值得一试的。MIT的Bill Freeman早期的代表作Steerable Filter在边缘检测方面效果也非常好，并且便于实现。这里给出了几篇比较好的文献，包括一篇最新的综述。边缘检测是图像处理和计算机视觉中任何方向都无法逃避的一个问题，这方面研究多深都不为过。
[1980] theory of edgedetection
[1983 Canny Thesis] findedge
[1986 PAMI] AComputational Approach to Edge Detection
[1990 PAMI] Scale-spaceand edge detection using anisotropic diffusion
[1991 PAMI] The design anduse of steerable filters
[1995 PR] Multiresolutionedge detection techniques
[1996 TIP] Optimal edgedetection in two-dimensional images
[1998 PAMI] Local ScaleControl for Edge Detection and Blur Estimation
[2003 PAMI] Statisticaledge detection_ learning and evaluating edge cues
[2004 IEEE] Edge DetectionRevisited
[2004 PAMI] Design ofsteerable filters for feature detection using canny-like criteria
[2004 PAMI] Learning toDetect Natural Image Boundaries Using Local Brightness, Color, and Texture Cues
[2011 IVC] Edge and lineoriented contour detection State of the art&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Graph Cut&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;基于图割的图像分割算法。在这方面没有研究，仅仅列出几篇引用比较高的文献。这里又见J Malik，当然还有华人杰出学者Jianbo Shi，他的主页非常搞笑，在醒目的位置标注Do not flyChina Eastern Airlines ... 看来是被坑过，而且坑的比较厉害。这个领域，俄罗斯人比较厉害。
[2000 PAMI] Normalizedcuts and image segmentation
[2001 PAMI] Fastapproximate energy minimization via graph cuts
[2004 PAMI] What energyfunctions can be minimized via graph cuts&lt;/p&gt;

&lt;p&gt;10.Hough Transform&lt;/p&gt;

&lt;p&gt;虽然霍夫变换可以扩展到广义霍夫变换，但最常用的还是检测圆和直线。这方面同样推荐看OpenCV的源代码，一目了然。Matas在2000年提出的PPHT已经集成到OpenCV中去了。
[1986 CVGIU] A Survey ofthe Hough Transform
[1989] A Comparative studyof Hough transform methods for circle finding
[1992 PAMI] Shapesrecognition using the straight line Hough transform_ theory and generalization
[1997 PR] Extraction ofline features in a noisy image
[2000 CVIU] RobustDetection of Lines Using the Progressive Probabilistic Hough Transform&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Image Interpolation&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;图像插值，偶尔也用得上。一般来说，双三次也就够了
[2000 TMI] Interpolationrevisited&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Image Matting&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;也就是最近，我才知道这个词翻译成中文是抠图，比较难听，不知道是谁开始这么翻译的。没有研究，请看文章以及Richard Szeliski的相关章节。以色列美女Levin在这方面有两篇PAMI。
[2008 Fnd] Image and VideoMatting A Survey
[2008 PAMI] A Closed-FormSolution to Natural Image Matting
[2008 PAMI] SpectralMatting&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Image Modeling&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;图像的统计模型。这方面有一本专门的著作Natural Image Statistics
[1994] The statistics ofnatural images
[2003 JMIV] On Advances inStatistical Modeling of Natural Images
[2009 IJCV] Fields ofExperts
[2009 PAMI] Modelingmultiscale subbands of photographic images with fields of Gaussian scalemixtures&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Image Quality Assessment&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;在图像质量评价方面，Bovik是首屈一指的。这位老师也很有意思，作为编辑出版了很多书。他也是IEEE的Fellow
[2004 TIP] Image qualityassessment from error visibility to structural similarity
[2011 TIP] blind imagequality assessment From Natural Scene Statistics to Perceptual Quality&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Image Registration&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;图像配准最早的应用在医学图像上，在图像融合之前需要对图像进行配准。在现在的计算机视觉中，配准也是一个需要理解的概念，比如跟踪，拼接等。在KLT中，也会涉及到配准。这里主要是综述文献。
[1992 MIA] Image matching asa diffusion process
[1992 PAMI] A Method forRegistration of 3-D shapes
[1992] a survey of imageregistration techniques
[1998 MIA] A survey ofmedical image registration
[2003 IVC] Imageregistration methods a survey
[2003 TMI]Mutual-Information-Based Registration of Medical Survey
[2011 TIP] Hairisregistration&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Image Retrieval&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;图像检索曾经很热，在2000年之后似乎消停了一段时间。最近各种图像的不变性特征提出来之后，再加上互联网搜索的商业需求，这个方向似乎又要火起来了，尤其是在工业界。这仍然是一个非常值得关注的方面。而且图像检索与目标识别具有相通之处，比如特征提取和特征降维。这方面的文章值得一读。在最后给出了两篇Book chapter，其中一篇还是中文的。
[2000 PAMI] Content-basedimage retrieval at the end of the early years
[2000 TIP] PicToSeekCombining Color and Shape Invariant Features for Image Retrieval
[2002] Content-Based ImageRetrieval Systems A Survey
[2008] Content-Based ImageRetrieval-Literature Survey
[2010] Plant ImageRetrieval Using Color,Shape and Texture Features
[2012 PAMI] A MultimediaRetrieval Framework Based on Semi-Supervised Ranking and Relevance Feedback
CBIR Chinese
fundament of cbir&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Image Segmentation&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;图像分割，非常基本但又非常难的一个问题。建议看Sonka和冈萨雷斯的书。这里给出几篇比较好的文章，再次看到了J Malik。他们给出了源代码和测试集，有兴趣的话可以试试。
[2004 IJCV] EfficientGraph-Based Image Segmentation
[2008 CVIU] Imagesegmentation evaluation A survey of unsupervised methods
[2011 PAMI] ContourDetection and Hierarchical Image Segmentation&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Level Set&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;大名鼎鼎的水平集，解决了Snake固有的缺点。Level set的两位提出者Sethian和Osher最后反目，实在让人遗憾。个人以为，这种方法除了迭代比较费时，在真实场景中的表现让人生疑。不过，2008年ECCV上的PWP方法在结果上很吸引人。在重初始化方面，Chunming Li给出了比较好的解决方案
[1995 PAMI] Shape modelingwith front propagation&lt;em&gt; a level set approach
[2001 JCP] Level SetMethods&lt;/em&gt; An Overview and Some Recent Results
[2005 CVIU] Geodesicactive regions and level set methods for motion estimation and tracking
[2007 IJCV] A Review ofStatistical Approaches to Level Set Segmentation
[2008 ECCV] RobustReal-Time Visual Tracking using Pixel-Wise Posteriors
[2010 TIP] DistanceRegularized Level Set Evolution and its Application to Image Segmentation&lt;/p&gt;

&lt;p&gt;19.Pyramid&lt;/p&gt;

&lt;p&gt;其实小波变换就是一种金字塔分解算法，而且具有无失真重构和非冗余的优点。Adelson在1983年提出的Pyramid优点是比较简单，实现起来比较方便。
[1983] The LaplacianPyramid as a Compact Image Code&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Radon Transform&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Radon变换也是一种很重要的变换，它构成了图像重建的基础。关于图像重建和radon变换，可以参考章毓晋老师的书，讲的比较清楚。
[1993 PAMI] Imagerepresentation via a finite Radon transform
[1993 TIP] The fastdiscrete radon transform I theory
[2007 IVC] Generalisedfinite radon transform for N×N images&lt;/p&gt;

&lt;p&gt;21.Scale Space&lt;/p&gt;

&lt;p&gt;尺度空间滤波在现代不变特征中是一个非常重要的概念，有人说SIFT的提出者Lowe是不变特征之父，而Linderburg是不变特征之母。虽然尺度空间滤波是Witkin最早提出的，但其理论体系的完善和应用还是Linderburg的功劳。其在1998年IJCV上的两篇文章值得一读，不管是特征提取方面还是边缘检测方面。
[1987] Scale-spacefiltering
[1990 PAMI] Scale-Spacefor Discrete Signals
[1994] Scale-space theoryA basic tool for analysing structures at different scales
[1998 IJCV] Edge Detectionand Ridge Detection with Automatic Scale Selection
[1998 IJCV] FeatureDetection with Automatic Scale Selection&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Snake&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;活动轮廓模型，改变了传统的图像分割的方法，用能量收缩的方法得到一个统计意义上的能量最小（最大）的边缘。
[1987 IJCV] Snakes ActiveContour Models
[1996 ] deformable modelin medical image A Survey
[1997 IJCV] geodesicactive contour
[1998 TIP] Snakes, shapes,and gradient vector flow
[2000 PAMI] Geodesic activecontours and level sets for the detection and tracking of moving objects
[2001 TIP] Active contourswithout edges&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Super Resolution&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;超分辨率分析。对这个方向没有研究，简单列几篇文章。其中Yang Jianchao的那篇在IEEE上的下载率一直居高不下。
[2002] Example-BasedSuper-Resolution
[2003 SPM] Super-Resolution Image Reconstruction A Technical Overview&lt;/p&gt;

&lt;p&gt;[2009 ICCV] Super-Resolutionfrom a Single Image
[2010 TIP] ImageSuper-Resolution Via Sparse Representation&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Thresholding&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;阈值分割是一种简单有效的图像分割算法。这个topic在冈萨雷斯的书里面讲的比较多。这里列出OTSU的原始文章以及一篇不错的综述。
[1979 IEEE] OTSU Athreshold selection method from gray-level histograms
[2001 JISE] A Fast Algorithmfor Multilevel Thresholding
[2004 JEI] Survey overimage thresholding techniques and quantitative performance evaluation&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Watershed&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;分水岭算法是一种非常有效的图像分割算法，它克服了传统的阈值分割方法的缺点，尤其是Marker-Controlled Watershed，值得关注。Watershed在冈萨雷斯的书里面讲的比较详细。
[1991 PAMI] Watersheds indigital spaces an efficient algorithm based on immersion simulations
[2001]The WatershedTransform Definitions, Algorithms and Parallelizat on Strategies&lt;/p&gt;

&lt;h2&gt;图像处理与计算机视觉：基础，经典以及最近发展（5）计算机视觉&lt;/h2&gt;

&lt;p&gt;Last update: 2012-6-7&lt;/p&gt;

&lt;p&gt;这一章是计算机视觉部分，主要侧重在底层特征提取，视频分析，跟踪，目标检测和识别方面等方面。对于自己不太熟悉的领域比如摄像机标定和立体视觉，仅仅列出上google上引用次数比较多的文献。有一些刚刚出版的文章，个人非常喜欢，也列出来了。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Active Appearance Models&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;活动表观模型和活动轮廓模型基本思想来源Snake，现在在人脸三维建模方面得到了很成功的应用，这里列出了三篇最初最经典的文章。对这个领域有兴趣的可以从这三篇文章开始入手。
[1998 ECCV] ActiveAppearance Models
[2001 PAMI] ActiveAppearance Models&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Active Shape Models&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;[1995 CVIU]Active ShapeModels-Their Training and Application&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Background modeling andsubtraction&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;背景建模一直是视频分析尤其是目标检测中的一项关键技术。虽然最近一直有一些新技术的产生，demo效果也很好，比如基于dynamical texture的方法。但最经典的还是Stauffer等在1999年和2000年提出的GMM方法，他们最大的贡献在于不用EM去做高斯拟合，而是采用了一种迭代的算法，这样就不需要保存很多帧的数据，节省了buffer。Zivkovic在2004年的ICPR和PAMI上提出了动态确定高斯数目的方法，把混合高斯模型做到了极致。这种方法效果也很好，而且易于实现。在OpenCV中有现成的函数可以调用。在背景建模大家族里，无参数方法（2000 ECCV）和Vibe方法也值得关注。
[1997 PAMI] PfinderReal-Time Tracking of the Human Body
[1999 CVPR] Adaptivebackground mixture models for real-time tracking
[1999 ICCV] WallflowerPrinciples and Practice of Background Maintenance
[2000 ECCV] Non-parametricModel for Background Subtraction
[2000 PAMI] LearningPatterns of Activity Using Real-Time Tracking
[2002 PIEEE] Backgroundand foreground modeling using nonparametric kernel density estimation forvisual surveillance
[2004 ICPR] Improvedadaptive Gaussian mixture model for background subtraction
[2004 PAMI] Recursiveunsupervised learning of finite mixture models
[2006 PRL] Efficientadaptive density estimation per image pixel for the task of backgroundsubtraction
[2011 TIP] ViBe AUniversal Background Subtraction Algorithm for Video Sequences&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Bag of Words&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;词袋，在这方面暂时没有什么研究。列出三篇引用率很高的文章，以后逐步解剖之。
[2003 ICCV] Video Google AText Retrieval Approach to Object Matching in Videos
[2004 ECCV] VisualCategorization with Bags of Keypoints
[2006 CVPR] Beyond bags offeatures Spatial pyramid matching for recognizing natural scene categories&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;BRIEF&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;BRIEF是BinaryRobust Independent Elementary Features的简称，是近年来比较受关注的特征描述的方法。ORB也是基于BRIEF的。
[2010 ECCV] BRIEF BinaryRobust Independent Elementary Features
[2011 ICCV] ORB anefficient alternative to SIFT or SURF
[2012 PAMI] BRIEFComputing a Local Binary Descriptor Very Fast&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Camera Calibration and StereoVision&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;非常不熟悉的领域。仅仅列出了十来篇重要的文献，供以后学习。
[1979 Marr] AComputational Theory of Human Stereo Vision
[1985] Computationalvision and regularization theory
[1987 IEEE] A versatilecamera calibration technique for high-accuracy 3D machine vision metrologyusing off-the-shelf TV cameras and lenses
[1987] ProbabilisticSolution of Ill-Posed Problems in Computational Vision
[1988 PIEEE] Ill-PosedProblems in Early Vision
[1989 IJCV] KalmanFilter-based Algorithms for Estimating Depth from Image Sequences
[1990 IJCV] RelativeOrientation
[1990 IJCV] Usingvanishing points for camera calibration
[1992 ECCV] Cameraself-calibration Theory and experiments
[1992 IJCV] A theory ofself-calibration of a moving camera
[1992 PAMI] Cameracalibration with distortion models and accuracy evaluation
[1994 IJCV] TheFundamental Matrix Theory, Algorithms, and Stability Analysis
[1994 PAMI] a stereomatching algorithm with an adaptive window theory and experiment
[1999 ICCV] Flexiblecamera calibration by viewing a plane from unknown orientations
[1999 IWAR] Markertracking and hmd calibration for a video-based augmented reality conferencingsystem
[2000 PAMI] A flexible newtechnique for camera calibration&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Color and Histogram Feature&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;这里面主要来源于图像检索，早期的图像检测基本基于全局的特征，其中最显著的就是颜色特征。这一部分可以和前面的Color知识放在一起的。
[1995 SPIE] Similarity ofcolor images
[1996 PR] IMAGE RETRIEVALUSING COLOR AND SHAPE
[1996] comparing imagesusing color coherence vectors
[1997 ] Image IndexingUsing Color Correlograms
[2001 TIP] An EfficientColor Representation for Image Retrieval
[2009 CVIU] Performanceevaluation of local colour invariants&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Deformable Part Model&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;大红大热的DPM，在OpenCV中有一个专门的topic讲DPM和latent svm
[2008 CVPR] ADiscriminatively Trained, Multiscale, Deformable Part Model
[2010 CVPR] Cascade ObjectDetection with Deformable Part Models
[2010 PAMI] ObjectDetection with Discriminatively Trained Part-Based Models&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Distance Transformations&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;距离变换，在OpenCV中也有实现。用来在二值图像中寻找种子点非常方便。
[1986 CVGIP] DistanceTransformations in Digital Images
[2008 ACM] 2D EuclideanDistance Transform Algorithms A Comparative Survey&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Face Detection&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;最成熟最有名的当属Haar+Adaboost
[1998 PAMI] NeuralNetwork-Based Face Detection
[2002 PAMI] Detectingfaces in images a survey
[2002 PAMI] Face Detectionin Color Images
[2004 IJCV] RobustReal-Time Face Detection&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Face Recognition&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;不熟悉，简单罗列之。
[1991] Face RecognitionUsing Eigenfaces
[2000 PAMI] AutomaticAnalysis of Facial Expressions The State of the Art
[2000] Face Recognition ALiterature Survey
[2006 PR] Face recognitionfrom a single image per person A survey
[2009 PAMI] Robust FaceRecognition via Sparse Representation&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;FAST&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;用机器学习的方法来提取角点，号称很快很好。
[2006 ECCV] Machinelearning for high-speed corner detection
[2010 PAMI] Faster andBetter A Machine Learning Approach to Corner Detection&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Feature Extraction&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;这里的特征主要都是各种不变性特征，SIFT，Harris，MSER等也属于这一类。把它们单独列出来是因为这些方法更流行一点。关于不变性特征，王永明与王贵锦合著的《图像局部不变性特征与描述》写的还不错。Mikolajczyk在2005年的PAMI上的文章以及2007年的综述是不错的学习材料。
[1989 PAMI] On thedetection of dominant points on digital curves
[1997 IJCV] SUSAN—A NewApproach to Low Level Image Processing
[2004 IJCV] MatchingWidely Separated Views Based on Affine Invariant Regions
[2004 IJCV] Scale &amp;amp;Affine Invariant Interest Point Detectors
[2005 PAMI] A performanceevaluation of local descriptors
[2006 IJCV] A Comparisonof Affine Region Detectors
[2007 FAT] Local InvariantFeature Detectors - A Survey
[2011 IJCV] Evaluation ofInterest Point Detectors and Feature Descriptors&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Feature Matching&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;[2012 PAMI] LDAHashImproved Matching with Smaller Descriptors&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Harris&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;虽然过去了很多年，Harris角点检测仍然广泛使用，而且基于它有很多变形。如果仔细看了这种方法，从直观也可以感觉到这是一种很稳健的方法。
[1988 Harris] A combinedcorner and edge detector&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Histograms of OrientedGradients&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;HoG方法也在OpenCV中实现了：HOGDescriptor。
[2005 CVPR] Histograms ofOriented Gradients for Human Detection
NavneetDalalThesis.pdf&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Image Distance&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;[1993 PAMI] ComparingImages Using the Hausdorff Distance&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Image Stitching&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;图像拼接，另一个相关的词是Panoramic。在Computer Vision: Algorithms and Applications一书中，有专门一章是讨论这个问题。这里的两面文章一篇是综述，一篇是这方面很经典的文章。
[2006 Fnd] Image Alignmentand Stitching A Tutorial
[2007 IJCV] AutomaticPanoramic Image Stitching using Invariant Features&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;KLT&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;KLT跟踪算法，基于Lucas-Kanade提出的配准算法。除了三篇很经典的文章，最后一篇给出了OpenCV实现KLT的细节。
[1981] An Iterative ImageRegistration Technique with an Application to Stereo Vision full version
[1994 CVPR] Good Featuresto Track
[2004 IJCV]  Lucas-Kanade 20 Years On A Unifying Framework
Pyramidal Implementationof the Lucas Kanade Feature Tracker OpenCV&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Local Binary Pattern&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;LBP。OpenCV的Cascade分类器也支持LBP，用来取代Haar特征。
[2002 PAMI]Multiresolution gray-scale and rotation Invariant Texture Classification withLocal Binary Patterns
[2004 ECCV] FaceRecognition with Local Binary Patterns
[2006 PAMI] FaceDescription with Local Binary Patterns
[2011 TIP]Rotation-Invariant Image and Video Description With Local Binary PatternFeatures&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Low-Level Vision&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;关于Low level vision的两篇很不错的文章
[1998 TIP] A generalframework for low level vision
[2000 IJCV] LearningLow-Level Vision&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Mean Shift&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;均值漂移算法，在跟踪中非常流行的方法。Comaniciu在这个方面做出了重要的贡献。最后三篇，一篇是CVIU上的top download文章，一篇是最新的PAMI上关于Mean Shift的文章，一篇是OpenCV实现的文章。
[1995 PAMI] Mean shift,mode seeking, and clustering
[2002 PAMI] Mean shift arobust approach toward feature space analysis
[2003 CVPR] Mean-shiftblob tracking through scale space
[2009 CVIU] Objecttracking using SIFT features and mean shift
[2012 PAMI] Mean ShiftTrackers with Cross-Bin Metrics
OpenCV Computer VisionFace Tracking For Use in a Perceptual User Interface&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;MSER&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;这篇文章发表在2002年的BMVC上，后来直接录用到2004年的IVC上，内容差不多。MSER在Sonka的书里面也有提到。
[2002 BMVC] Robust WideBaseline Stereo from Maximally Stable Extremal Regions
[2003] MSER AuthorPresentation
[2004 IVC] Robustwide-baseline stereo from maximally stable extremal regions
[2011 PAMI] Are MSERFeatures Really Interesting&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Object Detection&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;首先要说的是第一篇文章的作者，Kah-Kay Sung。他是MIT的博士，后来到新加坡国立任教，极具潜力的一个老师。不幸的是，他和他的妻子都在2000年的新加坡空难中遇难，让人唏嘘不已。
http://en.wikipedia.org/wiki/Singapore_Airlines_Flight_006
最后一篇文章也是Fua课题组的，作者给出的demo效果相当好。
[1998 PAMI] Example-basedlearning for view-based human face detection
[2000 CVPR] A Statistical Method for 3D Object Detection Applied to Faces and Cars
[2003 IJCV] Learning theStatistics of People in Images and Video
[2011 PAMI] Learning toDetect a Salient Object
[2012 PAMI] A Real-TimeDeformable Detector&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Object Tracking&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;跟踪也是计算机视觉中的经典问题。粒子滤波，卡尔曼滤波，KLT，mean shift，光流都跟它有关系。这里列出的是传统意义上的跟踪，尤其值得一看的是2008的Survey和2003年的Kernel based tracking。
[2003 PAMI] Kernel-basedobject tracking
[2007 PAMI] TrackingPeople by Learning Their Appearance
[2008 ACM] Object TrackingA Survey
[2008 PAMI] Segmentationand Tracking of Multiple Humans in Crowded Environments
[2011 PAMI] Hough Forestsfor Object Detection, Tracking, and Action Recognition
[2011 PAMI] Robust ObjectTracking with Online Multiple Instance Learning
[2012 IJCV] PWP3DReal-Time Segmentation and Tracking of 3D Objects&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;OCR&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;一个非常成熟的领域，已经很好的商业化了。
[1992 IEEE] Historical reviewof OCR research and development
Video OCR A Survey andPractitioner's Guide&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Optical Flow&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;光流法，视频分析所必需掌握的一种算法。
[1981 AI] DetermineOptical Flow
[1994 IJCV] Performance ofoptical flow techniques
[1995 ACM] The Computationof Optical Flow
[2004 TR] TutorialComputing 2D and 3D Optical Flow
[2005 BOOK] Optical FlowEstimation
[2008 ECCV] LearningOptical Flow
[2011 IJCV] A Database andEvaluation Methodology for Optical Flow&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Particle Filter&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;粒子滤波，主要给出的是综述以及1998 IJCV上的关于粒子滤波发展早期的经典文章。
[1998 IJCV] CONDENSATION—ConditionalDensity Propagation for Visual Tracking
[2002 TSP] A tutorial onparticle filters for online nonlinear non-Gaussian Bayesian tracking
[2002 TSP] Particlefilters for positioning, navigation, and tracking
[2003 SPM] particle filter&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Pedestrian and Human detection&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;仍然是综述类，关于行人和人体的运动检测和动作识别。
[1999 CVIU] Visualanalysis of human movement_ A survey
[2001 CVIU] A Survey ofComputer Vision-Based Human Motion Capture
[2005 TIP] Image changedetection algorithms a systematic survey
[2006 CVIU] a survey ofavdances in vision based human motion capture
[2007 CVIU] Vision-basedhuman motion analysis An overview
[2007 IJCV] PedestrianDetection via Periodic Motion Analysis
[2007 PR] A survey ofskin-color modeling and detection methods
[2010 IVC] A survey onvision-based human action recognition
[2012 PAMI] PedestrianDetection An Evaluation of the State of the Art&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Scene Classification&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;当相机越来越傻瓜化的时候，自动场景识别就非常重要。这是比拼谁家的Auto功能做的比较好的时候了。
[2001 IJCV] Modeling theShape of the Scene A Holistic Representation of the Spatial Envelope
[2001 PAMI] Visual WordAmbiguity
[2007 PAMI] A ThousandWords in a Scene
[2010 PAMI] EvaluatingColor Descriptors for Object and Scene Recognition
[2011 PAMI] CENTRIST AVisual Descriptor for Scene Categorization&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Shadow Detection&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;[2003 PAMI] Detectingmoving shadows-- algorithms and evaluation&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Shape&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;关于形状，主要是两个方面：形状的表示和形状的识别。形状的表示主要是从边缘或者区域当中提取不变性特征，用来做检索或者识别。这方面Sonka的书讲的比较系统。2008年的那篇综述在这方面也讲的不错。至于形状识别，最牛的当属J Malik等提出的Shape Context。
[1993 PR] IMPROVED MOMENTINVARIANTS FOR SHAPE DISCRIMINATION
[1993 PR] PatternRecognition by Affine Moment Invariants
[1996 PR] IMAGE RETRIEVALUSING COLOR AND SHAPE
[2001 SMI] Shape matchingsimilarity measures and algorithms
[2002 PAMI] Shape matchingand object recognition using shape contexts
[2004 PR] Review of shaperepresentation and description techniques
[2006 PAMI] IntegralInvariants for Shape Matching
[2008] A Survey of ShapeFeature Extraction Techniques&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;SIFT&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;关于SIFT，实在不需要介绍太多，一万多次的引用已经说明问题了。SURF和PCA-SIFT也是属于这个系列。后面列出了几篇跟SIFT有关的问题。
[1999 ICCV] Objectrecognition from local scale-invariant features
[2000 IJCV] Evaluation ofInterest Point Detectors
[2003 CVIU] Speeded-UpRobust Features (SURF)
[2004 CVPR] PCA-SIFT AMore Distinctive Representation for Local Image Descriptors
[2004 IJCV] DistinctiveImage Features from Scale-Invariant Keypoints
[2010 IJCV] ImprovingBag-of-Features for Large Scale Image Search
[2011 PAMI] SIFTflow DenseCorrespondence across Scenes and its Applications&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;SLAM&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Simultaneous Localization and Mapping, 同步定位与建图。
SLAM问题可以描述为: 机器人在未知环境中从一个未知位置开始移动,在移动过程中根据位置估计和地图进行自身定位,同时在自身定位的基础上建造增量式地图，实现机器人的自主定位和导航。
[2002 PAMI] SimultaneousLocalization and Map-Building Using Active Vision
[2007 PAMI] MonoSLAMReal-Time Single Camera SLAM&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Texture Feature&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;纹理特征也是物体识别和检索的一个重要特征集。
[1973] Textural featuresfor image classification
[1979 ] Statistical andstructural approaches to texture
[1996 PAMI] Texturefeatures for browsing and retrieval of image data
[2002 PR] Brief review ofinvariant texture analysis methods
[2012 TIP] Color LocalTexture Features for Color Face Recognition&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;TLD&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Kadal创立了TLD，跟踪学习检测同步进行，达到稳健跟踪的目的。他的两个导师也是大名鼎鼎，一个是发明MSER的Matas，一个是Mikolajczyk。他还创立了一个公司TLDVision s.r.o. 这里给出了他的系列文章，最后一篇是刚出来的PAMI。
[2009] Online learning ofrobust object detectors during unstable tracking
[2010 CVPR] P-N LearningBootstrapping Binary Classifiers by Structural Constraints
[2010 ICIP] FACE-TLDTRACKING-LEARNING-DETECTION APPLIED TO FACES
[2012 PAMI]Tracking-Learning-Detection&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Video Surveillance&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;前面两个是两个很有名的视频监控系统，里面包含了很丰富的信息量，比如CMU的那个系统里面的背景建模算法也是相当简单有效的。最后一篇是比较近的综述。
[2000 CMU TR] A System forVideo Surveillance and Monitoring
[2000 PAMI] W4-- real-timesurveillance of people and their activitie
[2008 MVA] The evolutionof video surveillance an overview&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Viola-Jones&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Haar+Adaboost的弱弱联手，组成了最强大的利器。在OpenCV里面有它的实现，也可以选择用LBP来代替Haar特征。
[2001 CVPR] Rapid objectdetection using a boosted cascade of simple features
[2004 IJCV] RobustReal-time Face Detection&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Cross Validation (An implementation to find the optimal parameters for LIBSVM)</title>
   <link href="http://lhzhang.com/2014/01/16/cross-validation.html"/>
   <updated>2014-01-16T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/16/cross-validation</id>
   <content type="html">&lt;h2&gt;Brief Introduction&lt;/h2&gt;

&lt;p&gt;Cross-validation, sometimes called rotation estimation, is a model validation technique for assessing how the results of a statistical analysis will generalize to an independent data set. It is mainly used in settings where the goal is prediction, and one wants to estimate how accurately a predictive model will perform in practice. It is worth highlighting that in a prediction problem, a model is usually given a dataset of known data on which training is run (training dataset), and a dataset of unknown data (or first seen data) against which the model is tested (testing dataset). The goal of cross validation is to define a dataset to &quot;test&quot; the model in the training phase (i.e., the validation dataset), in order to limit problems like overfitting, give an insight on how the model will generalize to an independent data set (i.e., an unknown dataset, for instance from a real problem), etc.&lt;/p&gt;

&lt;p&gt;One round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, multiple rounds of cross-validation are performed using different partitions, and the validation results are averaged over the rounds.&lt;/p&gt;

&lt;h2&gt;Common types of cross-validation&lt;/h2&gt;

&lt;h3&gt;K-fold cross-validation&lt;/h3&gt;

&lt;p&gt;In k-fold cross-validation, the original sample is randomly partitioned into k equal size subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining &lt;code&gt;k − 1&lt;/code&gt; subsamples are used as training data. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data. The k results from the folds can then be averaged (or otherwise combined) to produce a single estimation. The advantage of this method over repeated random sub-sampling is that all observations are used for both training and validation, and each observation is used for validation exactly once. 10-fold cross-validation is commonly used, but in general k remains an unfixed parameter.&lt;/p&gt;

&lt;h3&gt;2-fold cross-validation&lt;/h3&gt;

&lt;p&gt;This is the simplest variation of k-fold cross-validation. Also, called holdout method. For each fold, we randomly assign data points to two sets s0 and s1, so that both sets are equal size (this is usually implemented by shuffling the data array and then splitting it in two). We then train on s0 and test on s1, followed by training on s1 and testing on s0.&lt;/p&gt;

&lt;p&gt;This has the advantage that our training and test sets are both large, and each data point is used for both training and validation on each fold.&lt;/p&gt;

&lt;h3&gt;Repeated random sub-sampling validation&lt;/h3&gt;

&lt;p&gt;This method randomly splits the dataset into training and validation data. For each such split, the model is fit to the training data, and predictive accuracy is assessed using the validation data. The results are then averaged over the splits. The advantage of this method (over k-fold cross validation) is that the proportion of the training/validation split is not dependent on the number of iterations (folds). The disadvantage of this method is that some observations may never be selected in the validation subsample, whereas others may be selected more than once. In other words, validation subsets may overlap. This method also exhibits Monte Carlo variation, meaning that the results will vary if the analysis is repeated with different random splits.&lt;/p&gt;

&lt;h3&gt;Leave-one-out cross-validation&lt;/h3&gt;

&lt;p&gt;Leave-one-out cross-validation (LOOCV) involves using a single observation from the original sample as the validation data, and the remaining observations as the training data. This is repeated such that each observation in the sample is used once as the validation data. This is the same as a K-fold cross-validation with K being equal to the number of observations in the original sampling.&lt;/p&gt;

&lt;h2&gt;An example: 10-fold cross-validation&lt;/h2&gt;

&lt;p&gt;将数据集分成十分，轮流将其中9份作为训练数据，1份作为测试数据，进行试验。每次试验都会得出相应的正确率（或差错率）。10次的结果的正确率（或差错率）的平均值作为对算法精度的估计，一般还需要进行多次10-fold cross-validation（例如10次10-fold cross-validation），再求其均值，作为对算法准确性的估计。&lt;/p&gt;

&lt;p&gt;之所以选择将数据集分为10份，是因为通过利用大量数据集、使用不同学习技术进行的大量试验，表明10折是获得最好误差估计的恰当选择，而且也有一些理论根据可以证明这一点。但这并非最终诊断，争议仍然存在。而且似乎5折或者20折与10折所得出的结果也相差无几。&lt;/p&gt;

&lt;h2&gt;An implementation of cross-validation to find the optimal parameters for LIBSVM.&lt;/h2&gt;

&lt;p&gt;The artical and source code are in &lt;a href=&quot;http://imkaywu.com/2014/01/15/find-the-optimal-parameter.html&quot;&gt;another post&lt;/a&gt;, go check it out.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hand Gesture Recognition</title>
   <link href="http://lhzhang.com/2014/01/16/Hand-gesture-recognition.html"/>
   <updated>2014-01-16T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/16/Hand-gesture-recognition</id>
   <content type="html">&lt;p&gt;This is a post that gives a brief description of the algorithm of hand gesture recognition that I developed. It serves as a reminder of what has been done and what remains to be done. You can download the codes in &lt;a href=&quot;https://github.com/imkaywu/Gesture-Recognition-SVM&quot;&gt;Github&lt;/a&gt;, feel free to try out and change the code.Let me introduce our algorithm step by step.&lt;/p&gt;

&lt;blockquote&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/Find-the-contour-of-the-hand-gestures.html&quot;&gt;Find the contour points and connect them in a consecutive manner&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/Find-the-centroid-of-the-hand-gestures.html&quot;&gt;Find the centroid of hand gesture using &lt;strong&gt;distance transform&lt;/strong&gt;.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/Find-the-direction-of-hand-gestures.html&quot;&gt;Find the direction of the hand gesture using the relative positions of contour points (using just Step 1).&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/Transform-to-time-series-curve.html&quot;&gt;Transform the hand contour (points above the centroid, which contribute more to the hand direction) into a &lt;em&gt;time-series curve&lt;/em&gt;.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2014/01/12/Find-the-fingertips-and-fingerroots.html&quot;&gt;Find the initial positions of the fingertips and fingerroots (using just Step 1).&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2014/01/12/Find-the-fingertips-and-fingerroots.html&quot;&gt;Refine the positions of fingertips and fingerroots(using Step 2).&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/Find-the-direction-of-hand-gestures.html&quot;&gt;Find the accurate direction of the hand gesture using the directions of fingers(using Step 2).&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/two-recognition-schemes.html&quot;&gt;Recognition scheme 1: Use the positions of the fingertips and fingerroots for recognition.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://imkaywu.com/2013/11/23/two-recognition-schemes.html&quot;&gt;Recognition scheme 2: Transform the contour points into the time-series curve again and take samples. For each gesture, we can obtain a feature vector. Use Machine Learning algorithm to train the data for recognition.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is pretty much everything about our hand gesture recognition algorithm, the source code is constantly changing because I am still refining the algorithm. If you are interested, please go to my &lt;a href=&quot;https://github.com/imkaywu/&quot;&gt;Github page&lt;/a&gt; to download the &lt;a href=&quot;https://github.com/imkaywu/Gesture-Recognition-SVM&quot;&gt;latest version&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Find the optimal parameters for LIBSVM using cross-validation</title>
   <link href="http://lhzhang.com/2014/01/15/find-the-optimal-parameter.html"/>
   <updated>2014-01-15T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/15/find-the-optimal-parameter</id>
   <content type="html">&lt;h3&gt;目标&lt;/h3&gt;

&lt;p&gt;在SVM算法中，通过交叉验证来确定最佳的参数&lt;code&gt;c&lt;/code&gt;和&lt;code&gt;g&lt;/code&gt;。&lt;/p&gt;

&lt;h3&gt;想法：&lt;/h3&gt;

&lt;p&gt;让c和g在一定的范围里跑(比如 c = 2&lt;sup&gt;(-5),2&lt;sup&gt;(-4),...,2&lt;sup&gt;(5),g&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt; = 2&lt;sup&gt;(-5),2&lt;sup&gt;(-4),...,2&lt;sup&gt;(5)),然后用cross&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt; validation的想法找到准确率最高的c和g,在这里我做了一点修改(纯粹是个人的一点小经验和想法),我改进的是: 因为会有不同的c和g都对应最高的的准确率,我把具有最小c的那组c和g认为是最佳的c和g,因为惩罚参数不能设置太高,很高的惩罚参数能使得validation数据的准确率提高,但过高的惩罚参数c会造成过学习状态,反正从我用SVM到现在,往往都是惩罚参数c过高会导致最终测试集合的准确率并不是很理想。&lt;/p&gt;

&lt;h3&gt;Code:&lt;/h3&gt;

&lt;p&gt;寻找最优化参数的函数(implemented using 10-fold cross-validation)：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function [bestacc,bestc,bestg] = SVMcg(train_label,train,cmin,cmax,gmin,gmax,v,cstep,gstep,accstep)
    % train_label:训练集标签.要求与libsvm工具箱中要求一致.
    % train:训练集.要求与libsvm工具箱中要求一致.
    % cmin:惩罚参数c的变化范围的最小值(取以2为底的对数后),即 c_min = 2^(cmin).默认为 -5
    % cmax:惩罚参数c的变化范围的最大值(取以2为底的对数后),即 c_max = 2^(cmax).默认为 5
    % gmin:参数g的变化范围的最小值(取以2为底的对数后),即 g_min = 2^(gmin).默认为 -5
    % gmax:参数g的变化范围的最小值(取以2为底的对数后),即 g_min = 2^(gmax).默认为 5
    % 
    % v:cross validation的参数,即给测试集分为几部分进行cross validation.默认为 3
    % cstep:参数c步进的大小.默认为 1
    % gstep:参数g步进的大小.默认为 1
    % accstep:最后显示准确率图时的步进大小. 默认为 1.5
    %% about the parameters of SVMcg
    v_def = 10;
    if nargin &amp;lt; 10
        accstep = 1.5;
    end
    if nargin &amp;lt; 8
        accstep = 1.5;
        cstep = 1;
        gstep = 1;
    end
    if nargin &amp;lt; 7
        accstep = 1.5;
        v = v_def;
        cstep = 1;
        gstep = 1;
    end
    if nargin &amp;lt; 6
        accstep = 1.5;
        v = v_def;
        cstep = 1;
        gstep = 1;
        gmax = 5;
    end
    if nargin &amp;lt; 5
        accstep = 1.5;
        v = v_def;
        cstep = 1;
        gstep = 1;
        gmax = 5;
        gmin = -5;
    end
    if nargin &amp;lt; 4
        accstep = 1.5;
        v = v_def;
        cstep = 1;
        gstep = 1;
        gmax = 5;
        gmin = -5;
        cmax = 5;
    end
    if nargin &amp;lt; 3
        accstep = 1.5;
        v = v_def;
        cstep = 1;
        gstep = 1;
        gmax = 5;
        gmin = -5;
        cmax = 5;
        cmin = -5;
    end
    %% X:c Y:g cg:acc
    [X,Y] = meshgrid(cmin:cstep:cmax,gmin:gstep:gmax);
    [m,n] = size(X);
    cg = zeros(m,n);
    %% record acc with different c &amp;amp; g,and find the bestacc with the smallest c
    bestc = 0;
    bestg = 0;
    bestacc = 0;
    basenum = 2;
    for i = 1:m
        for j = 1:n
            cmd = ['-v ',num2str(v),' -c ',num2str( basenum^X(i,j) ),' -g ',num2str( basenum^Y(i,j) )];
            cg(i,j) = svmtrain(train_label, train, cmd);

            if ( cg(i,j) &amp;gt; bestacc || ( cg(i,j) == bestacc &amp;amp;&amp;amp; bestc &amp;gt; basenum^X(i,j) ) )
                bestacc = cg(i,j);
                bestc = basenum^X(i,j);
                bestg = basenum^Y(i,j);
            end
        end
    end
    %% to draw the acc with different c &amp;amp; g
    [C,h] = contour(X,Y,cg,60:accstep:100);
    clabel(C,h,'FontSize',10,'Color','r');
    xlabel('log2c','FontSize',10);
    ylabel('log2g','FontSize',10);
    grid on;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;函数的测试程序：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[ bestacc , bestc , bestg ] = SVMcg( input_feature , train_set );
cmd = [ '-c ' , num2str(bestc) , ' -g ' , num2str(bestg) ];
model = svmtrain( input_feature , train_set , cmd );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;http://www.ilovematlab.cn/thread-47819-1-1.html&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Find the position of fingertips and fingervalleys</title>
   <link href="http://lhzhang.com/2014/01/12/Find-the-fingertips-and-fingerroots.html"/>
   <updated>2014-01-12T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/12/Find-the-fingertips-and-fingerroots</id>
   <content type="html">&lt;h3&gt;Step 1&lt;/h3&gt;

&lt;p&gt;After obtaining the &lt;em&gt;time-series curve&lt;/em&gt;, we can find the positions of the fingertips and fingerroots.&lt;/p&gt;

&lt;p&gt;The fingertips are definded as the locally highest point and the fingervalleys as locally lowest ones. The result of the initial detection of fingertips and fingervalleys is shown below.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The initial detection of fingertips and fingervalleys&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/fingertip&amp;amp;fingervalley.png&quot; alt=&quot;initially detected fingertips and fingervalleys&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then the valid fingertips and their corresponding fingerroots are selected from these candidate points. This is done as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for each fingertip
    find out all the fingervalleys that are on the left and right side of this fingertip (ft), denoted as fv_l and fv_r;
    eliminate invalid fingervalleys using prior knowledge of hand geometry;
    optimal_function(ft,fv_l);
    optimal_function(ft,fv_r);
    find out the fingervalley that maximize the optimal function *optimal_function* and this is regarded as the two fingerroots of this fingertip
endfor
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result of the algorithm is shown as follows. The optimal function I adopt is&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;optimal_function = (distance_ft - distance_fv) ./ distance_fv - 2.5 * (degree_ft - degree_fv) ./ degree_fv;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;The modified detection of fingertips and fingervalleys in both original image and time-series curve&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/fingertip&amp;amp;fingerroot2.png&quot; alt=&quot;detection fingertips and fingerroots&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/fingertip&amp;amp;fingerroot1.png&quot; alt=&quot;detection fingertips and fingerroots&quot; /&gt;
For some images, there are still some refinement needed. For instance, more than 1 detected fingertips may share one or both the fingerroot(s), so there is another optimal function needed to select one fingertip, the optimal function is as follows&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;optimal_function = distance_ft - 0.5 * (distance_fr_l + distance_fr_r);&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Here is the source code of the algorithm written in MATLAB&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function [fingerroot,fingertip]=finger_finder2(degree,norm_distance)
    j=1;
    firstTime=1;
    finger_edge=1;
    length=size(degree,2);
    fingertip=zeros(5,1);
    fingertip_remain=zeros(5,1);
    fingervalley=zeros(1,6);
    fingerroot=zeros(5,2);
    fingerroot_remain=zeros(5,2);
    min_distance=norm_distance(1);
    max_distance=norm_distance(1);
    for i=1:length
        if(norm_distance(i)&amp;lt;min_distance)
            min_distance=norm_distance(i);
            max_distance=norm_distance(i);
            if(min_distance&amp;lt;norm_distance(finger_edge))
                finger_edge=i;
            end
        elseif(norm_distance(i)&amp;lt;max_distance)
            fingertip(j)=i-1;
            fingervalley(j)=finger_edge;
            j=j+1;
            firstTime=~firstTime;
            min_distance=norm_distance(i);
            max_distance=norm_distance(i);
        elseif(norm_distance(i)&amp;gt;max_distance)
            if(firstTime)
                finger_edge=i-1;
                firstTime=~firstTime;
            end
            max_distance=norm_distance(i);
        end
    end

    j=1;
    fingertip_length=find(fingertip,1,'last');
    fingervalley(fingertip_length+1)=size(degree,2);
    for i=1:fingertip_length
        index_left=i;
        index_right=i+1;
        if(i==7)
        end
        if(sum(fingertip_remain)==0||max(norm_distance(fingertip(fingertip_remain(1:find(fingertip_remain,1,'last')))))&amp;lt;norm_distance(fingertip(i)))
            fv_left_all=fingervalley(1:index_left);
        else
            [ft_highest,ft_highest_index]=max(norm_distance(fingertip(fingertip_remain(1:find(fingertip_remain,1,'last')))));
            ft_highest_index=fingertip_remain(ft_highest_index);
            fv_left_all=fingervalley(ft_highest_index+1:index_left);
        end
        fv_right_all=fingervalley(index_right:fingertip_length+1);
%         fv_left_all(norm_distance(fv_left_all)&amp;gt;1.85)=[];
%         fv_right_all(norm_distance(fv_right_all)&amp;gt;1.85)=[];
        fv_left_index=(norm_distance(fingertip(i))-norm_distance(fv_left_all))./norm_distance(fv_left_all)&amp;gt;0.49;
        fv_right_index=(norm_distance(fingertip(i))-norm_distance(fv_right_all))./norm_distance(fv_right_all)&amp;gt;0.49;
        fv_left_all=fv_left_all(fv_left_index);
        fv_right_all=fv_right_all(fv_right_index);

        if(sum(fv_left_index)~=0&amp;amp;&amp;amp;size(fv_left_all,2)&amp;gt;1)
            optim_func_left=(norm_distance(fingertip(i))-norm_distance(fv_left_all))./norm_distance(fv_left_all)-2.5*(degree(fingertip(i))-degree(fv_left_all))./degree(fv_left_all);
            [maxVal,maxInd]=max(optim_func_left);
            fv_left_all=fv_left_all(maxInd);
        end

        if(sum(fv_right_index)~=0&amp;amp;&amp;amp;size(fv_right_index,2)&amp;gt;1)
            optim_func_right=(norm_distance(fingertip(i))-norm_distance(fv_right_index))./norm_distance(fv_right_index)-2.5*(degree(fv_right_index)-degree(fingertip(i)))./degree(fv_right_index);
            [maxVal,maxInd]=max(optim_func_right);
            fv_right_all=fv_right_all(maxInd);
        end

        if(sum(fv_left_index)==0||sum(fv_right_index)==0)
            continue;
        else
            fingertip_remain(j)=i;
            fingerroot_remain(j,:)=[fv_left_all,fv_right_all];
            j=j+1;
        end
    end
    index=find(fingertip_remain==0);
    fingertip_remain(index)=[];
    fingertip_remain=fingertip(fingertip_remain);
    fingerroot_remain(index,:)=[];

    %Eliminate the combinations of fingertip and fingerroots of which the
    %fingerroots are out of bounds
    n=1;
    fingertip_remove=zeros(1,size(fingertip_remain,1));
    for i=1:size(fingertip_remain,1)-1
        for j=i+1:size(fingertip_remain,1)
            if(fingerroot_remain(i,1)&amp;gt;=fingerroot_remain(j,1)||fingerroot_remain(i,2)&amp;gt;fingerroot_remain(j,1))%between the two numbers
                if(sum((norm_distance(fingertip_remain(i))-norm_distance(fingerroot_remain(i,:)))./norm_distance(fingerroot_remain(i,:)))&amp;gt;sum((norm_distance(fingertip_remain(j))-norm_distance(fingerroot_remain(j,:)))./norm_distance(fingerroot_remain(j,:))))
                    fingertip_remove(n)=j;
                else
                    fingertip_remove(n)=i;
                end
                n=n+1;
            end
        end
    end
    fingertip_remove(fingertip_remove==0)=[];
    fingertip_remove=unique(fingertip_remove);
    fingertip_remain(fingertip_remove)=[];
%     fingertip_remain=unique(fingertip_remain);
    fingerroot_remain(fingertip_remove,:)=[];

    %Find out the fingertips that have one more two same fingerroot(s) 
    fingervalley_cato=zeros(size(fingertip_remain,1));
    flag=zeros(1,size(fingertip_remain,1));
    for i=1:size(fingertip_remain,1)-1
        for j=i+1:size(fingertip_remain,1)
            if(sum(fingerroot_remain(i,:)==fingerroot_remain(j,:))&amp;amp;&amp;amp;flag(j)==0)
                fingervalley_cato(i,[2*(j-i)-1,2*(j-i)])=[i,j];
                flag([i,j])=1;
            end
        end
    end

    n=1;
    fingertip=zeros(5,1);
    if(size(fingertip_remain,1)~=1&amp;amp;&amp;amp;sum(sum(fingervalley_cato))~=0)
        for i=1:size(fingervalley_cato,1)
            fingervalley_cato_temp=fingervalley_cato(i,:);
            if(sum(fingervalley_cato_temp)~=0)
                fingertip_index=unique(fingervalley_cato_temp(fingervalley_cato_temp~=0));
                optim_func=zeros(size(fingertip_index,2),1);
                for j=1:size(fingertip_index,2)
                    optim_func(j)=norm_distance(fingertip_remain(fingertip_index(j)))-mean(norm_distance(fingerroot_remain(fingertip_index(j),:)));
                end
                [a,fingertip_pos]=max(optim_func);
                fingertip_pos=fingertip_index(fingertip_pos);
                fingertip(n)=fingertip_remain(fingertip_pos);
                fingerroot(n,:)=fingerroot_remain(fingertip_pos,:);
                n=n+1;
            elseif(flag(i)==0)
                fingertip(n)=fingertip_remain(i);
                fingerroot(n,:)=fingerroot_remain(i,:);
                n=n+1;
            end
        end
    else
        fingertip=fingertip_remain;
        fingerroot=fingerroot_remain;
    end

    finger_remove=fingertip==0;
    fingertip(finger_remove)=[];
    fingerroot(finger_remove,:)=[];
    [fingertip,ft_index]=sort(fingertip);
    fingerroot=fingerroot(ft_index,:);

    if(find(fingertip,1,'last')&amp;gt;1&amp;amp;&amp;amp;(degree(fingerroot(1,2))-degree(fingerroot(1,1)))/(norm_distance(fingertip(1))-mean(norm_distance(fingerroot(1,:))))&amp;gt;0.3)%used to solve noise peak in gesture4 image7
        fingertip(1)=[];
        fingerroot(1,:)=[];
    end

%     figure;
%     plot(degree,norm_distance);
%     hold on;
%     plot(degree(fingertip),norm_distance(fingertip),'r^');
%     plot(degree(fingerroot),norm_distance(fingerroot),'ro');
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After the fingertips and fingerroots are found, they are still in need of some adjustment in order to achievement the best performance. Therefore Step 2 is employed to further refine the positions of fingertips and fingerroots.&lt;/p&gt;

&lt;h3&gt;Step 2&lt;/h3&gt;

&lt;p&gt;It's intuitive to us that if we draw a external rectangle to each finger, the ratio of the area of the finger and the rectangular area should surpass a certain threshold. So this is the main idea of the algorithm to precisely locate the positions of the fingerroots.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;area_ratio = area_finger / area_external_rec;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;First, with the positions of the fingertip and fingerroots, we can know the direction of the finger, which is obtained as follows&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;finger_direction = 0.5 * (direction_ft_fr_l + direction_ft_fr_r);&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then we find the mirror point for each of the fingerroot(the line crosses one fingerroot and its mirror point is perpendicular to finger direction). And whichever combination(fingerroot and its mirror point) is closer to the fingertip, we treat them as the updated fingerroots. Then we calculate the &lt;em&gt;area_ratio&lt;/em&gt;. This process repeats until the &lt;em&gt;area_ratio&lt;/em&gt; surpass a certain threshold. In our code, I use 0.65 as the threshold.&lt;/p&gt;

&lt;p&gt;Here is the refined positions of fingertips and fingerroot, as you can see the differences when compared to the initial ones above. Source code is as follows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The refined detection of fingertips and fingervalleys&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/images/fingertip&amp;amp;fingerroot_refined.png&quot; alt=&quot;refined detection fingertips and fingervalleys&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%% ----detect the more accurate positions of the fingerroots---- %%
fingertip_length=size(fingertip,1);
fingerroot=zeros(1,2*fingertip_length);
finger_direction=zeros(1,fingertip_length);
for i=1:fingertip_length
    P=[y_array(fingertip(i)),x_array(fingertip(i))];
    fingeredge_start=fingervalley(i,1);
    fingeredge_end=fingervalley(i,2);
    while(true)
        direction_angle=direction_detector3(x_array,y_array,fingertip(i),[fingeredge_start,fingeredge_end]);
        [fingeredge_start,fingeredge_end]=finger_finder3(x_array,y_array,fingertip(i),[fingeredge_start,fingeredge_end],direction_angle);
        %calculate the area of the external rectangle
        Q=[P(1)+10,P(2)-10/tand(direction_angle)];
        n=1;
        dist=zeros(1,fingeredge_end-fingeredge_start+1);
        for j=fingeredge_start:fingeredge_end
            dist(n)=abs(det([P-Q;[y_array(j),x_array(j)]-Q]))/norm(P-Q);
            n=n+1;
        end
        fingerroot1=[y_array(fingeredge_start),x_array(fingeredge_start)];
        fingerroot2=[y_array(fingeredge_end),x_array(fingeredge_end)];
        length=max(dist(1:fingertip(i)-fingeredge_start+1))+max(dist(fingertip(i)-fingeredge_start+1:fingeredge_end-fingeredge_start+1));
        height=abs(det([fingerroot2-fingerroot1;P-fingerroot1]))/norm(fingerroot2-fingerroot1);
        area=length*height;
        %calculate the area of the finger
        finger_area=0;
        finger_top=min(y_array(fingeredge_start:fingeredge_end));
        up=min(y_array([fingeredge_start,fingeredge_end]));
        low=max(y_array([fingeredge_start,fingeredge_end]));
        for j=finger_top:1:low
            if(j&amp;lt;=up)
                x=x_array(fingeredge_start+find(j==y_array(fingeredge_start:fingeredge_end))-1);
                finger_area=finger_area+max(x)-min(x)+1;
            else
                if(up==y_array(fingeredge_end))
                    x=x_array(fingeredge_end)+(x_array(fingeredge_end)-x_array(fingeredge_start))/(up-low)*(j-up);
                    finger_area=finger_area+x-min(x_array(fingeredge_start+find(j==y_array(fingeredge_start:fingeredge_end))-1))+1;
                else
                    x=x_array(fingeredge_start)+(x_array(fingeredge_start)-x_array(fingeredge_end))/(up-low)*(j-up);
                    finger_area=finger_area+max(x_array(fingeredge_start+find(j==y_array(fingeredge_start:fingeredge_end))-1))-x+1;
                end
            end
        end
%             imshow(edge_map);
%             hold on;
%             x_line1=zeros(1,row);
%             y_line=1:row;
%             x_line1(1:y_array(fingertip(i)))=x_array(fingertip(i))+round((y_array(fingertip(i))-(1:y_array(fingertip(i))))./tand(direction_angle));
%             x_line1(y_array(fingertip(i))+1:row)=x_array(fingertip(i))-round(((y_array(fingertip(i))+1:row)-y_array(fingertip(i)))./tand(direction_angle));
%             plot(x_line1,y_line);
%             plot([x_array(fingeredge_start),x_array(fingeredge_end)],[y_array(fingeredge_start),y_array(fingeredge_end)],'r*');

        area_percent=finger_area/area;
        if(area_percent&amp;gt;0.65||(fingeredge_start&amp;gt;fingertip(i)||fingeredge_end&amp;lt;fingertip(i)))
            fingerroot([2*i-1,2*i])=[fingeredge_start,fingeredge_end];
            finger_direction(i)=direction_angle;
            break;
        end
    end
end
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>SVM多分类的方法 (转载)</title>
   <link href="http://lhzhang.com/2014/01/10/SVM%E5%A4%9A%E5%88%86%E7%B1%BB%E7%9A%84%E6%96%B9%E6%B3%95.html"/>
   <updated>2014-01-10T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/10/SVM多分类的方法</id>
   <content type="html">&lt;p&gt;SVM算法最初是为二值分类问题设计的，当处理多类问题时，就需要构造合适的多类分类器。目前，构造SVM多类分类器的方法主要有两类：一类是直接法，直接在目标函数上进行修改，将多个分类面的参数求解合并到一个最优化问题中，通过求解该最优化问题“一次性”实现多类分类。这种方法看似简单，但其计算复杂度比较高，实现起来比较困难，只适合用于小型问题中；另一类是间接法，主要是通过组合多个二分类器来实现多分类器的构造，常见的方法有one-against-one和one-against-all两种。&lt;/p&gt;

&lt;p&gt;a.一对多法（one-versus-rest,简称1-v-r SVMs）。训练时依次把某个类别的样本归为一类,其他剩余的样本归为另一类，这样k个类别的样本就构造出了k个SVM。分类时将未知样本分类为具有最大分类函数值的那类。&lt;/p&gt;

&lt;p&gt;b.一对一法（one-versus-one,简称1-v-1 SVMs）。其做法是在任意两类样本之间设计一个SVM，因此k个类别的样本就需要设计k(k-1)/2个SVM。当对一个未知样本进行分类时，最后得票最多的类别即为该未知样本的类别。Libsvm中的多类分类就是根据这个方法实现的。&lt;/p&gt;

&lt;p&gt;c.层次支持向量机（H-SVMs）。层次分类法首先将所有类别分成两个子类，再将子类进一步划分成两个次级子类，如此循环，直到得到一个单独的类别为止。&lt;/p&gt;

&lt;p&gt;对c和d两种方法的详细说明可以参考论文《支持向量机在多类分类问题中的推广》（计算机工程与应用。2004）&lt;/p&gt;

&lt;p&gt;d.其他多类分类方法。除了以上几种方法外，还有有向无环图SVM（Directed Acyclic Graph SVMs，简称DAG-SVMs）和对类别进行二进制编码的纠错编码SVMs。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/lanseliuying/article/details/1768995&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>LIBSVP简介和安装使用</title>
   <link href="http://lhzhang.com/2014/01/10/LIBSVM.html"/>
   <updated>2014-01-10T00:00:00+08:00</updated>
   <id>http://lhzhang.com/2014/01/10/LIBSVM</id>
   <content type="html">&lt;h2&gt;简介&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;LIBSVM&lt;/a&gt;是台湾大学林智仁教授等研究人员开发的一个用于支持向量机分类，回归分析及分布估计的c/c++开源库。另外，它也可以用于解决多类分类问题。LIBSVM的主要特点有：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;各种SVM的表达公式；&lt;/p&gt;

&lt;p&gt;有效的多类分类能力；&lt;/p&gt;

&lt;p&gt;交叉验证功能；&lt;/p&gt;

&lt;p&gt;各种核函数，包括预先计算得到的核矩阵；&lt;/p&gt;

&lt;p&gt;用于非平衡数据的加权svm；&lt;/p&gt;

&lt;p&gt;提供c++和java源代码；&lt;/p&gt;

&lt;p&gt;用于演示SVM分类与回归能力的GUI界面；&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;林智仁教授推荐按照以下的步骤来使用LIBSVM：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;将数据转换到LIBSVM指定的格式；&lt;/p&gt;

&lt;p&gt;对数据进行尺度操作（一般指数据的归一化）；&lt;/p&gt;

&lt;p&gt;考虑RBF（径向基）核函数；&lt;/p&gt;

&lt;p&gt;利用交叉验证来得到最好的参数C和r；&lt;/p&gt;

&lt;p&gt;用最好的C和r来训练所有训练集合；&lt;/p&gt;

&lt;p&gt;测试；&lt;/p&gt;&lt;/blockquote&gt;

&lt;h2&gt;安装&lt;/h2&gt;

&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/cjlin1/libsvm&quot;&gt;下载LIBSVM软件包&lt;/a&gt;,将该软件包解压缩到MATLAB所在目录下的toolbox文件夹下。&lt;/p&gt;

&lt;p&gt;选择编译器： 因为LIBSVM是用C++写的， 为了能在MATLAB中使用，必须通过编译器将C++代码编译成MATLAB可执行的代码（.mexw32）。在MATLAB命令窗口中输入&lt;code&gt;mex -setup&lt;/code&gt;，然后按照提示选择编译器即可。&lt;/p&gt;

&lt;p&gt;编译：编译时必须在LIBSVM/matlab的目录下，执行&lt;code&gt;make&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;测试：下载测试使用的数据heart_scale.mat(注：有C++版本和MATLAB版，要下载MATLAB版本)。然后执行以下命令：&lt;/p&gt;&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;load heart_scale;
model=svmtrain(heart_scale_label,heart_scale_inst);
[predict_label,accuracy,prob_estimates] = svmpredict(heart_scale_label,heart_scale_inst,model,'b');
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果成功的话就可以看到Accuracy。其中heart_scale_label是train的标签，heart_scale_inst是train的feature vector，model是SVM训练出来的模型。&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
